{
  "quiz": {
    "questions": [
      {
        "id": 1,
        "question": "Which of the following are good use cases for how Amazon ElastiCache can help an application? (Select TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Improve the performance of S3 PUT operations",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Improve the latency of deployments performed by AWS CodeDeploy",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Improve latency and throughput for read-heavy application workloads",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Reduce the time required to merge AWS CodeCommit branches",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "Improve performance of compute-intensive applications",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 2,
        "question": "Which of the following services are key/value stores? (Choose 3 answers)",
        "answers": [
          {
            "id": "1",
            "text": "Amazon ElastiCache",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Simple Notification Service",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "DynamoDB",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Simple Workflow Service",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "Simple Storage Service",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 3,
        "question": "A developer wants to send multi-value headers to an AWS Lambda function that is registered as a target with an Application Load Balancer (ALB). What should the developer do to achieve this?",
        "answers": [
          {
            "id": "1",
            "text": " Place the Lambda function and target group in the same account",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Send the request body to the Lambda function with a size less than 1 MB 0",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Include the Base64 encoding status status code, status description, and headers in the Lambda function",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Enable the multi-value headers on the ALB",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 4,
        "question": "A company's ecommerce website is experiencing massive traffic spikes, which are causing performance problems in the company database. Users are reporting that accessing the website takes a long time. A developer wants to implement a caching layer using Amazon ElastiCache. The website is required to be responsive no matter which product a user views, and the updates to product information and prices must be strongly consistent. Which cache writing policy will satisfy these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Write to the cache directly and sync the backend at a later time",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Write to the backend first and wait for the cache to expire",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Write to the cache and the backend at the same time",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Write to the backend first and invalidate the cache",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 5,
        "question": "A Developer wants to upload data to Amazon S3 and must encrypt the data in transit. Which of the following solutions will accomplish this task? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Set up hardware VPN tunnels to a VPC and access S3 through a VPC endpoint",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Set up Client-Side Encryption with an AWS KMS-Managed Customer Master Key",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Set up Server-Side Encryption with AWS KMS-Managed Keys",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Transfer the data over an SSL connectionSet up Server-Side Encryption with S3-Managed Keys",
            "isCorrect": true
          },
          {
            "id": "5",
            "text": "Set up Server-Side Encryption with S3-Managed Keys",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 6,
        "question": "A Developer wants to encrypt new objects that are being uploaded to an Amazon S3 bucket by an application. There must be an audit trail of who has used the key during this process. There should be no change to the performance of the application. Which type of encryption meets these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Server-side encryption using S3-managed keys",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Server-side encryption with AWS KMS-managed keys",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Client-side encryption with a client-side symmetric master key",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Client-side encryption with AWS KMS-managed keys",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 7,
        "question": "An application is being developed to audit several AWS accounts. The application will run in Account A and must access AWS services in Accounts B and C. What is the MOST secure way to allow the application to call AWS services in each audited account?",
        "answers": [
          {
            "id": "1",
            "text": "Configure cross-account roles in each audited account. Write code in Account A that assumes those roles",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Use S3 cross-region replication to communicate among accounts, with Amazon S3 event notifications to trigger Lambda functions",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Deploy an application in each audited account with its own role. Have Account A authenticate with the application",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create an IAM user with an access key in each audited account. Write code in Account A that uses those access keys",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 8,
        "question": "A company uses a third-party tool to build, bundle, and package rts applications on-premises and store them locally. The company uses Amazon EC2 instances to run its front-end applications. How can an application be deployed from the source control system onto the EC2 instances?",
        "answers": [
          {
            "id": "1",
            "text": "Use AWS CodeDeploy and point it to the local storage to directly deploy a bundle m a zip. tar. or tar.gz format",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Upload the bundle to an Amazon S3 bucket and specify the S3 location when doing a deployment using AWS CodeDeploy",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Create a repository using AWS CodeCommit to automatically trigger a deployment to the EC2 instances",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use AWS CodeBuild to automatically deploy the latest build to the latest EC2 instances",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 9,
        "question": "A company is building a compute-intensive application that will run on a fleet of Amazon EC2 instances. The application uses attached Amazon EBS disks for storing data. The application will process sensitive information and all the data must be encrypted. What should a developer do to ensure the data is encrypted on disk without impacting performance?",
        "answers": [
          {
            "id": "1",
            "text": "Configure the Amazon EC2 instance fleet to use encrypted EBS volumes for storing data",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Add logic to write all data to an encrypted Amazon S3 bucket",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Add a custom encryption algorithm to the application that will encrypt and decrypt all data",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create a new Amazon Machine Image (AMI) with an encrypted root volume and store the data to ephemeral disks",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 10,
        "question": "A global company has an application running on Amazon EC2 instances that serves image files from Amazon S3. User requests from the browser are causing high traffic, which results in degraded performance. Which optimization solution should a Developer implement to increase application performance?",
        "answers": [
          {
            "id": "1",
            "text": "Create multiple prefix in the S3 bucket to increase the request rate",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create an Amazon ElastiCache cluster to cache and serve frequently accessed items",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use Amazon CloudFront to serve the content of images stored in Amazon S3",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Submit a ticket to AWS support to request a rate limit increase for the S3 bucket",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 11,
        "question": "An AWS Lambda function generates a 3MB JSON file and then uploads it to an Amazon S3 bucket daily. The file contains sensitive information, so the Developer must ensure that it is encrypted before uploading to the bucket. Which of the following modifications should the Developer make to ensure that the data is encrypted before uploading it to the bucket?",
        "answers": [
          {
            "id": "1",
            "text": "Use the default AWS KMS customer master key for S3 in the Lambda function code",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use the S3 managed key and call the GenerateDataKey API to encrypt the file",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use the GenerateDataKey API, then use that data key to encrypt the file in the Lambda function code",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Use a custom KMS customer master key created for S3 in the Lambda function code",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 12,
        "question": "Company D is running their corporate website on Amazon S3 accessed from http://www.companyd.com. Their marketing team has published new web fonts to a separate S3 bucket accessed by the S3 endpoint https://s3-us-west-1.amazonaws.com/cdfonts. While testing the new web fonts, Company D recognized the web fonts are being blocked by the browser. What should Company D do to prevent the web fonts from being blocked by the browser?",
        "answers": [
          {
            "id": "1",
            "text": "Enable versioning on the cdfonts bucket for each web font",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create a policy on the cdfonts bucket to enable access to everyone",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Add the Content-MD5 header to the request for webfonts in the cdfonts bucket from the website",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Configure the cdfonts bucket to allow cross-origin requests by creating a CORS configuration",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 13,
        "question": "A developer must extend an existing application that is based on the AWS Services Application Model (AWS SAM). The developer has used the AWS SAM CLI to create the project. The project contains different AWS Lambda functions. Which combination of commands must the developer use to redeploy the AWS SAM application? (Select TWO)",
        "answers": [
          {
            "id": "1",
            "text": "sam init",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "sam validate",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "sam build",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "sam deploy",
            "isCorrect": true
          },
          {
            "id": "5",
            "text": "sam publish",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 14,
        "question": "An application deployed on AWS Elastic Beanstalk experiences increased error rates during deployments of new application versions, resulting in service degradation for users. The Development team believes that this is because of the reduction in capacity during the deployment steps. The team would like to change the deployment policy configuration of the environment to an option that maintains full capacity during deployment while using the existing instances. Which deployment policy will meet these requirements while using the existing instances?",
        "answers": [
          {
            "id": "1",
            "text": "All at once",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Rolling",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Rolling with additional batch",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Immutable",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 15,
        "question": "A Developer is creating an application that needs to locate the public IPv4 address of the Amazon EC2 instance on which it runs. How can the application locate this information?",
        "answers": [
          {
            "id": "1",
            "text": "Get the instance metadata by retrieving http://169.254.169.254/latest/metadata/",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Get the instance user data by retrieving http://169.254.169.254/latest/userdata/",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Get the application to run IFCONFIG to get the public IP address",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Get the application to run IFCONFIG to get the public IP address",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 16,
        "question": "The development team is working on an API that will be served from Amazon API gateway. The API will be served from three environments: development, test, and production. The API Gateway is configured to use 237 GB of cache in all three stages. Which is the MOST cost-efficient deployment strategy?",
        "answers": [
          {
            "id": "1",
            "text": "Create a single API Gateway with all three stages",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create three API Gateways, one for each stage in a single AWS account",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create an API Gateway in three separate AWS accounts",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Enable the cache for development and test environments only when needed",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 17,
        "question": "A company is migrating its on-premises database to Amazon RDS for MySQL. The company has read-heavy workloads, and wants to make sure it re-factors its code to achieve optimum read performance for its queries. How can this objective be met?",
        "answers": [
          {
            "id": "1",
            "text": "Add database retries to effectively use RDS with vertical scaling",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use RDS with multi-AZ deployment",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Add a connection string to use an RDS read replica for read queries",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Add a connection string to use a read replica on an EC2 instance",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 18,
        "question": "A developer needs to modify an application architecture to meet new functional requirements. Application data is stored in Amazon DynamoDB and processed for analysis in a nightly batch. The system analysts do not want to wait unit the next day to view the processed data and have asked to have it available in near-real time. Which application architect pattern would enables the data to be processed as it is received?",
        "answers": [
          {
            "id": "1",
            "text": "Event driven",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Client served driven",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Fan-out driven",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Schedule driven",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 19,
        "question": "q19 - placeholder question (reminder to self: remove this once dev is done)",
        "answers": [
          {
            "id": "1",
            "text": "ans 1",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "ans 2",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "ans 3",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "ans 4",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "ans 5",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 20,
        "question": "A software company needs to make sure user-uploaded documents are securely stored in Amazon S3. The documents must be encrypted at rest in Amazon S3. The company does not want to manage the security infrastructure in-house, but the company still needs extra protection to ensure it has control over its encryption keys due to industry regulations. Which encryption strategy should a developer use to meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Server-side encryption with Amazon S3 managed keys (SSE-S3)",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Server-side encryption with customer-provided encryption keys (SSE-C)",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Server-side encryption with AWS KMS managed keys (SSE-KMS)",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Client-side encryption",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 21,
        "question": "An application uses Amazon Kinesis Data Streams to ingest and process large streams of data records in real time. Amazon EC2 instances consume and process the data from the shards of the Kinesis data stream by using Amazon Kinesis Client Library (KCL). The application handles the failure scenarios and does not require standby workers. The application reports that a specific shard is receiving more data than expected. To adapt to the changes in the rate of data flow, the 'hot' shard is resharded. Assuming that the initial number of shards in the Kinesis data stream is 4, and after resharding the number of shards increased to 6, what is the maximum number of EC2 instances that can be deployed to process data from all the shards?",
        "answers": [
          {
            "id": "1",
            "text": "12",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "6",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "4",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "1",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 22,
        "question": "A gaming company is developing a mobile game application for iOS® and Android® platforms. This mobile game securely stores user data locally on the device. The company wants to allow users to use multiple device for the game, which requires user data synchronization across device.Which service should be used to synchronize user data across devices without the need to create a backend application?",
        "answers": [
          {
            "id": "1",
            "text": "AWS Lambda",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Amazon S3",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon DynamoDB",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Amazon Cognito",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 23,
        "question": "A Developer is making changes to a custom application that is currently using AWS Elastic Beanstalk. After the Developer completes the changes, what solutions will update the Elastic Beanstalk environment with the new application version? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Package the application code into a .zip file, and upload, then deploy the packaged application from the AWS Management Console",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Package the application code into a .tar file, create a new application version from the AWS Management Console, then update the environment by using AWS CLI",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Package the application code into a .tar file, and upload and deploy the packaged application from the AWS Management Console",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Package the application code into a .zip file, create a new application version from the packaged application by using AWS CLI, then update the environment by using AWS CLI",
            "isCorrect": true
          },
          {
            "id": "5",
            "text": "Package the application code into a .zip file, create a new application version from the AWS Management Console, then rebuild the environment by using AWS CLI",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 24,
        "question": "A company is running an application built on AWS Lambda functions. One Lambda function has performance issues when it has to download a 50MB file from the Internet in every execution. This function is called multiple times a second. What solution would give the BEST performance increase?",
        "answers": [
          {
            "id": "1",
            "text": "Cache the file in the /tmp directory",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Increase the Lambda maximum execution time",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Put an Elastic Load Balancer in front of the Lambda function",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Cache the file in Amazon S3",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 25,
        "question": "Queries to an Amazon DynamoDB table are consuming a large amount of read capacity. The table has a significant number of large attributes. The application does not need all of the attribute data. How can DynamoDB costs be minimized while maximizing application performance?",
        "answers": [
          {
            "id": "1",
            "text": "Batch all the writes, and perform the write operations when no or few reads are being performed",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create a global secondary index with a minimum set of projected attributes",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Implement exponential backoffs in the application",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Load balance the reads to the table using an Application Load Balancer",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 26,
        "question": "A Developer is writing a REST service that will add items to a shopping list. The service is built on Amazon API Gateway with AWS Lambda integrations. The shopping list items are send as query string parameters in the method request. How should the Developer convert the query string parameters to arguments for the Lambda function?",
        "answers": [
          {
            "id": "1",
            "text": "Enable request validation",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Include the Amazon Resource Name (ARN) of the Lambda function",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Change the integration type",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create a mapping template",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 27,
        "question": "A development team is creating a new application designed to run on AWS. While the test and production environments will run on Amazon EC2 instances, developers will each run their own environment on their laptops. Which of the following is the simplest and MOST secure way to access AWS services from the local development machines?",
        "answers": [
          {
            "id": "1",
            "text": "Use an IAM role to assume a role and execute API calls using the role",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create an IAM user to be shared with the entire development team, provide the development team with the access key",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": " Create an IAM user for each developer on the team: provide each developer with a unique access key",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Set up a federation through an Amazon Cognito user pool",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 28,
        "question": "How is provisioned throughput affected by the chosen consistency model when reading data from a DynamoDB table?",
        "answers": [
          {
            "id": "1",
            "text": "Strongly consistent reads use the same amount of throughput as eventually consistent reads",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Strongly consistent reads use more throughput than eventually consistent reads",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Strongly consistent reads use less throughput than eventually consistent reads",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Strongly consistent reads use variable throughput depending on read activity",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 29,
        "question": "A developer needs to deploy a new version to an AWS Elastic Beanstalk application. How can the developer accomplish this task?",
        "answers": [
          {
            "id": "1",
            "text": "Upload and deploy the new application version in the Elastic Beanstalk console",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Use the eb init CLI command to deploy a new version",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Terminate the current Elastic Beanstalk environment and create a new one",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Modify the ebextensions folder to add a source option to services",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 30,
        "question": "A gaming application stores scores for players in an Amazon DynamoDB table that has four attributes: user_id, user_name, user_score, and user_rank. The users are allowed to update their names only if a user is authenticated by web identity federation. Which set of conditions should be added in the policy attached to the role for the DynamoDB: PutItem API call?",
        "answers": [
          {
            "id": "1",
            "text": "Condition: {ForAllValues:StringEquals: {dynamodb:LeadingKeys: [${www.amazon.com:user+id}], dynamodb:Attributes: [user_name]}}",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Condition:{ForAllValues:StringEquals:{dynamodb:LeadingKeys: [${www.amazon.com:user_name}], dynamodb:Attributes:[user_id]}}",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Condition:{ForAllValues:StringEquals:{dynamodb:LeadingKeys: [${www.amazon.com:user_id}], dynamodb:Attributes:[user_name, user_id]}}",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Condition:{ForAllValues:StringEquals:{dynamodb:LeadingKeys:[${www.amazon.com:user_name}], dynamodb:Attributes:[user_name, user_id]}}",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 31,
        "question": "A developer wants the ability to roll back to a previous version of an AWS Lambda function in the event of errors caused by a new deployment. How can the developer achieve this with MINIMAL impact on users?",
        "answers": [
          {
            "id": "1",
            "text": "Change the application to use an alias that points to the current version. Deploy the new version of the code. Update the alias to use the newly deployed version. If too many errors are encountered, point the alias back to the previous version",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Change the application to use an alias that points to the current version. Deploy the new version of the code. Update the alias to direct 10% of users to the newly deployed version. If too many errors are encountered, send 100% of traffic to the previous version",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Do not make any changes to the application Deploy the new version of the code. If too many errors are encountered, point the application back to the previous version using the version number in the Amazon Resource Name (ARN)",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create three aliases: new, existing, and router. Point the existing alias to the current version. Have the router alias direct 100% of users to the existing alias. Update the application to use the router alias. Deploy the new version of the code. Point the new alias to this version. Update the router alias to direct 10% of users to the new alias. If too many errors are encountered, send 100% of traffic to the existing alias",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 32,
        "question": "An application contains two components: one component to handle HTTP requests, and another component to handle background processing tasks. Each component must scale independently. The developer wants to deploy this application using AWS Elastic Beanstalk. How should this application be deployed, based on these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Deploy the application in a single Elastic Beanstalk environment",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Deploy each component in a separate Elastic Beanstalk environment",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Use multiple Elastic Beanstalk environments for the HTTP component but one environment for the background task component",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use multiple Elastic Beanstalk environments for the background task component but one environment for the HTTP component",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 33,
        "question": "A company is using AWS CloudFormation templates to deploy AWS resources. The company needs to update one of its AWS CloudFormation stacks. What can the company do to find out how the changes will impact the resources that are running?",
        "answers": [
          {
            "id": "1",
            "text": "Investigate the change sets",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Investigate the stack policies",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Investigate the Metadata section",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Investigate the Resources section",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 34,
        "question": "A developer is creating a serverless web application and maintains different branches of code. The developer wants to avoid updating the Amazon API Gateway target endpoint each time a new code push is performed. What solution would allow the developer to perform a code push efficiently, without the need to update the API Gateway?",
        "answers": [
          {
            "id": "1",
            "text": "Associate different AWS Lambda functions to an API Gateway target endpoint",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create different stages in API Gateway, then associate API Gateway with aws Lambda",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create aliases and versions In AWS Lambda",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Tag the AWS Lambda functions with different names",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 35,
        "question": "An application running on EC2 instances is storing data in an S3 bucket. Security policy mandates that all data must be encrypted in transit. How can the Developer ensure that all traffic to the S3 bucket is encrypted?",
        "answers": [
          {
            "id": "1",
            "text": "Install certificates on the EC2 instances",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create a bucket policy that allows traffic where SecureTransport is true",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Create an HTTPS redirect on the EC2 instances",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create a bucket policy that denies traffic where SecureTransport is false",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 36,
        "question": "A supplier is writing a new RESTful API for customers to query the status of orders. The customers requested the following API endpoint http://www.supplierdomain.com/status/customerID. Which of the following application designs meet the requirements? (Select TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Amazon SQS; Amazon SNS",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Elastic Load Balancing; Amazon EC2",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Amazon ElastiCache; Amazon Elacticsearch Service",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Amazon API Gateway; AWS Lambda",
            "isCorrect": true
          },
          {
            "id": "5",
            "text": "Amazon S3; Amazon CloudFront",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 37,
        "question": "A developer Is designing an AWS Lambda function that create temporary files that are less than 10 MB during execution. The temporary files will be accessed and modified multiple times during execution. The developer has no need to save or retrieve these files in the future. Where should the temporary file be stored?",
        "answers": [
          {
            "id": "1",
            "text": "the /tmp directory",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Amazon EFS",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon EBS",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Amazon S3",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 38,
        "question": "A website's page load times are gradually increasing as more users access the system at the same time. Analysis indicates that a user profile is being loaded from a database in all the web pages being visited by each user and this is increasing the database load and the page load latency. To address this issue the Developer decides to cache the user profile data. Which caching strategy will address this situation MOST efficiently?",
        "answers": [
          {
            "id": "1",
            "text": "Create a new Amazon EC2 Instance and run a NoSQL database on it. Cache the profile data within this database using the write-through caching strategy",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create an Amazon ElastiCache cluster to cache the user profile data. Use a cache-aside caching strategy",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Use a dedicated Amazon RDS instance for caching profile data. Use a write-through caching strategy",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create an ElastiCache cluster to cache the user profile data. Use a write-through caching strategy",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 39,
        "question": "An advertising company has a dynamic website with heavy traffic. The company wants to migrate the website infrastructure to AWS to handle everything except website development. Which solution BEST meets these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Use AWS VM Import to migrate a web server image to AWS Launch the image on a compute-optimized Amazon EC2 instance",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Launch multiple Amazon Lightsail instance behind a load balancer. Set up the website on those instances",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Deploy the website code in an AWS Elastic Beanstalk environment. Use Auto Scaling to scale the numbers of instance",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Use Amazon S3 to host the website. Use Amazon CloudFront to deliver the content at scale",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 40,
        "question": "A developer is writing an AWS Lambda function. The developer wants to log key events that occur during the Lambda function and include a unique identifier to associate the events with a specific function invocation. Which of the following will help the developer accomplish this objective?",
        "answers": [
          {
            "id": "1",
            "text": "Obtain the request identifier from the Lambda context object. Architect the application to write logs to the console",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Obtain the request identifier from the Lambda event object. Architect the application to write logs to a file",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Obtain the request identifier from the Lambda event object. Architect the application to write logs to the console",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Obtain the request identifier from the Lambda context object. Architect the application to write logs to a file",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 41,
        "question": "A company stores all personally identifiable information (PII) in an Amazon DynamoDB table named PII in Account A. An application running on Amazon EC2 instances in Account B requires access to the PII table. An administrators in Account A created an IAM role named AccessPII with privileges to access the PII table, and made account B a trusted entity. Which combination of actional steps should Developers take to access the table? (Select TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Allow the EC2 IAM role the permission to assume the AccessPII role",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Allow the EC2 IAM role the permission to access the PII table",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Include the AWS API in the application code logic to obtain temporary credentials from the EC2 IAM role to access the PII table",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Include the AssumeRole API operation in the application code logic to obtain temporary credentials to access the PII table",
            "isCorrect": true
          },
          {
            "id": "5",
            "text": "Include the GetSessionToken API operation in the application code logic to obtain temporary credentials to access the PII table",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 42,
        "question": "An AWS Lambda function accesses two Amazon DynamoDB tables. A developer wants to improve the performance of the Lambda function by identifying bottlenecks in the function. How can the developer inspect the timing of the DynamoDB API calls?",
        "answers": [
          {
            "id": "1",
            "text": "Add DynamoDB as an event source to the Lambda function. View the performance with Amazon CloudWatch metrics",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Place an Application Load Balancer (ALB) in front of the two DynamoDB tables. Inspect the ALB logs",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Limit Lambda to no more than five concurrent invocations Monitor from the Lambda console",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Enable AWS X-Ray tracing for the function. View the traces from the X-Ray service",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 43,
        "question": "An Amazon RDS database instance is used by many applications to look up historical data. The query rate is relatively constant. When the historical data is updated each day, the resulting write traffic slows the read query performance and affects all application users. What can be done to eliminate the performance impact on application users?",
        "answers": [
          {
            "id": "1",
            "text": "Make sure Amazon RDS is Multi-AZ so it can better absorb increased traffic",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create an RDS Read Replica and direct all read traffic to the replica",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Implement Amazon ElastiCache in front of Amazon RDS to buffer the write traffic",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use Amazon DynamoDB instead of Amazon RDS to buffer the read traffic",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 44,
        "question": "A company is developing a serverless ecommerce web application. The application needs to make coordinated, all-or-nothing changes to multiple items in the company's inventory table in Amazon DynamoDB. Which solution will meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Enable transactions for the DynamoDB table. Use the BatchWriteltem operation to update the items",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use the TransactWriteitems operation to group the changes. Update the items in the table",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Set up a FIFO queue using Amazon SQS. Group the changes in the queue. Update the table based on the grouped changes",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create a transaction table in an Amazon Aurora DB cluster to manage the transactions. Write a backend process to sync the Aurora DB table and the DynamoDB table",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 45,
        "question": "An application is running on an EC2 instance. The Developer wants to store an application metric in Amazon CloudWatch. What is the best practice for implementing this requirement?",
        "answers": [
          {
            "id": "1",
            "text": "Use the PUT Object API call to send data to an S3 bucket. Use an event notification to invoke a Lambda function to publish data to CloudWatch",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Publish the metric data to an Amazon Kinesis Stream using a PutRecord API call. Subscribe a Lambda function that publishes data to CloudWatch",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use the CloudWatch PutMetricData API call to submit a custom metric to CloudWatch. Provide the required credentials to enable the API call",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use the CloudWatch PutMetricData API call to submit a custom metric to CloudWatch. Launch the EC2 instance with the required IAM role to enable the API call",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 46,
        "question": "A Developer needs to design an application running on AWS that will be used to consume Amazon SQS messages that range from 1 KB up to 1GB in size. How should the Amazon SQS messages be managed?",
        "answers": [
          {
            "id": "1",
            "text": "Use Amazon S3 and the Amazon SQS CLI",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use Amazon S3 and the Amazon SQS Extended Client Library for Java",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Use Amazon EBS and the Amazon SQS CLI",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use Amazon EFS and the Amazon SQS CLI",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 47,
        "question": "A developer has written a multi-threaded application that is running on a fleet of Amazon EC2 instances. The operations team has requested a graphical method to monitor the number of running threads over time. What is the MOST efficient way to fulfill this request?",
        "answers": [
          {
            "id": "1",
            "text": "Periodically send the thread count to AWS X-Ray segments, then generate a service graph on demand",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create a custom Amazon CloudWatch metric and periodically perform a PutMetricData call with the current thread count",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Periodically log thread count data to Amazon S3. Use Amazon Kinesis to process the data into a graph",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Periodically write the current thread count to a table using Amazon DynamoDB and use Amazon CloudFront to create a graph",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 48,
        "question": "[reminder: add the image in] The Lambda function below is being called through an API using Amazon API Gateway. The average execution time for the Lambda function is about 1 second. The pseudocode for the Lambda function is as shown in the exhibit. What two actions can be taken to improve the performance of this Lambda function without increasing the cost of the solution? (Select TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Package only the modules the Lambda function requires",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Use Amazon DynamoDB instead of Amazon RDS",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Move the initialization of the variable Amazon RDS connection outside of the handler function",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Implement custom database connection pooling with the Lambda function",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "Implement local caching of Amazon RDS data so Lambda can re-use the cache",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 49,
        "question": "An application on AWS is using third-party APIs. The Developer needs to monitor API errors in the code, and wants to receive notifications if failures go above a set threshold value. How can the Developer achieve these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Publish a custom metric on Amazon CloudWatch and use Amazon Simple Email Service (SES) for notification",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use an Amazon CloudWatch API-error metric and use Amazon Simple Notification Service (SNS) for notification",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use an Amazon CloudWatch API-error metric and use Amazon SES for notification",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Publish a custom metric on Amazon CloudWatch and use Amazon SNS for notification",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 50,
        "question": "The release process workflow of an application requires a manual approval before the code is deployed into the production environment. What is the BEST way to achieve this using AWS CodePipeline?",
        "answers": [
          {
            "id": "1",
            "text": "Use multiple pipelines to allow approval",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use an approval action in a stage",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Disable the stage transition to allow manual approval",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Disable a stage just prior the deployment stage",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 51,
        "question": "A Developer is asked to implement a caching layer in front of Amazon RDS. Cached content is expensive to regenerate in case of service failure. Which implementation below would work while maintaining maximum uptime?",
        "answers": [
          {
            "id": "1",
            "text": "Implement Amazon ElastiCache Redis in Cluster Mode",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Install Redis on an Amazon EC2 instance",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Implement Amazon ElastiCache Memcached",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Migrate the database to Amazon Redshift",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 52,
        "question": "A company has written a Java AWS Lambda function to be triggered whenever a user uploads an image to an Amazon S3 bucket. The function converts the original image to several different formats and then copies the resulting images to another Amazon S3 bucket. The Developers find that no images are being copied to the second Amazon S3 bucket. They have tested the code on an Amazon EC2 instance with 1GB of RAM, and it takes an average of 500 seconds to complete. What is the MOST likely cause of the problem?",
        "answers": [
          {
            "id": "1",
            "text": "The Lambda function has insufficient memory and needs to be increased to 1 GB to match the Amazon EC2 instance",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Files need to be copied to the same Amazon S3 bucket for processing, so the second bucket needs to be deleted",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Lambda functions have a maximum execution limit of 15 minutes, therefore the function is not completing",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "There is a problem with the Java runtime for Lambda, and the function needs to be converted to node.js",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 53,
        "question": "A web application is using Amazon Kinesis Streams for clickstream data that may not be consumed for up to 12 hours. How can the Developer implement encryption at rest for data within the Kinesis Streams?",
        "answers": [
          {
            "id": "1",
            "text": "Enable SSL connections to Kinesis",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use Amazon Kinesis Consumer Library",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Encrypt the data once it is at rest with a Lambda function",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Enable server-side encryption in Kinesis Streams",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 54,
        "question": "A Developer is creating a mobile application with a limited budget. The solution requires a scalable service that will enable customers to sign up and authenticate into the mobile application while using the organization's current SAML 2.0 identity provider. Which AWS service should be used to meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "AWS Lambda",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Amazon Cognito",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "AWS IAM",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Amazon EC2",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 55,
        "question": "A company wants to migrate its web application to AWS and leverage Auto Scaling to handle peak workloads. The Solutions Architect determined that the best metric for an Auto Scaling event is the number of concurrent users. Based on this information, what should the Developer use to autoscale based on concurrent users?",
        "answers": [
          {
            "id": "1",
            "text": "An Amazon SNS topic to be triggered when a concurrent user threshold is met",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "An Amazon Cloudwatch NetworkIn metric",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon CloudFront to leverage AWS Edge Locations",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "A Custom Amazon CloudWatch metric for concurrent users",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 56,
        "question": "A Developer has written a serverless application using multiple AWS services. The business logic is written as a Lambda function which has dependencies on third-party libraries. The Lambda function endpoints will be exposed using Amazon API Gateway. The Lambda function will write the information to Amazon DynamoDB. The Developer is ready to deploy the application but must have the ability to rollback. How can this deployment be automated, based on these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Deploy using Amazon Lambda API operations to create the Lambda function by providing a deployment package",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use an AWS CloudFormation template and use CloudFormation syntax to define the Lambda function resource in the template.",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use syntax conforming to the Serverless Application Model in the AWS CloudFormation template to define the Lambda function resource",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Create a bash script which uses AWS CLI to package and deploy the application",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 57,
        "question": "A game stores user game data in an Amazon DynamoDB table. Individual users should not have access to other users' game data. How can this be accomplished?",
        "answers": [
          {
            "id": "1",
            "text": "Encrypt the game data with individual user keys",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Restrict access to specific items based on certain primary key values",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Stage data in SQS queues to inject metadata before accessing DynamoDB",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Read records from DynamoDB and discard irrelevant data client-side",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 58,
        "question": "A Developer is creating a web application that requires authentication, but also needs to support guest access to provide users limited access without having to authenticate. What service can provide support for the application to allow guest access?",
        "answers": [
          {
            "id": "1",
            "text": "IAM temporary credentials using AWS STS",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Amazon Directory Service",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon Cognito with unauthenticated access enabled",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "IAM with SAML integration",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 59,
        "question": "[reminder: add image/code block] Given the source code for an AWS Lambda function in the local store.py containing a handler function called get_store and the following AWS CloudFormation template. What should be done to prepare the template so that it can be deployed using the AWS CLI command aws cloudformation deploy?",
        "answers": [
          {
            "id": "1",
            "text": "Use AWS CloudFormation compile to base64 encode and embed the source file into a modified CloudFormation template",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use AWS CloudFormation package to upload the source code to an Amazon S3 bucket and produce a modified CloudFormation template",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Use AWS Lambda zip to package the source file together with the CloudFormation template and deploy the resulting zip archive",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use AWS Serverless create-package to embed the source file directly into the existing CloudFormation template",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 60,
        "question": "A Developer has created a large Lambda function, and deployment is failing with the following error:ClientError: An error occurred (InvalidParameterValueException) when calling the CreateFunction operation: Unzipped size must be smaller than XXXXXXXXX bytes', where XXXXXXXXX is the current Lambda limit. What can the Developer do to fix this problem?",
        "answers": [
          {
            "id": "1",
            "text": "Submit a limit increase request to AWS Support to increase the function to the size needed",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use a compression algorithm that is more efficient than ZIP",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Break the function into multiple smaller Lambda functions",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "ZIP the ZIP file twice to compress it further",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 61,
        "question": "A serverless application uses an API Gateway and AWS Lambda. Where should the Lambda function store its session information across function calls?",
        "answers": [
          {
            "id": "1",
            "text": "In an Amazon DynamoDB table",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "In an Amazon SQS queue",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "In the local filesystem",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "In an SQLite session table using CDSQLITE_ENABLE_SESSION",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 62,
        "question": "An application reads data from an Amazon DynamoDB table. Several times a day, for a period of 15 seconds, the application receives multiple ProvisionedThroughputExceeded errors. How should this exception be handled?",
        "answers": [
          {
            "id": "1",
            "text": "Create a new global secondary index for the table to help with the additional requests",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Retry the failed read requests with exponential backoff",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Immediately retry the failed read requests",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use the DynamoDB 'UpdateItem' API to increase the provisioned throughput capacity of the table",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 63,
        "question": "A Developer is writing a Linux-based application to run on AWS Elastic Beanstalk. Application requirements state that the application must maintain full capacity during updates while minimizing cost. Which type of Elastic Beanstalk deployment policy should the Developer specify for the environment?",
        "answers": [
          {
            "id": "1",
            "text": "Immutable",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Rolling",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "All at Once",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Rolling with additional batch",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 64,
        "question": "When writing a Lambda function, what is the benefit of instantiating AWS clients outside the scope of the handler?",
        "answers": [
          {
            "id": "1",
            "text": "Legibility and stylistic convention",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Taking advantage of connection re-use",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Better error handling",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Creating a new instance per invocation",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 65,
        "question": "A current architecture uses many Lambda functions invoking one another as large state machine. The coordination of this state machine is legacy custom code that breaks easily. Which AWS Service can help refactor and manage the state machine?",
        "answers": [
          {
            "id": "1",
            "text": "AWS Data Pipeline",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "AWS SNS with AWS SQS",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon Elastic MapReduce",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "AWS Step Functions",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 66,
        "question": "A company is developing a new online game that will run on top of Amazon ECS. Four distinct Amazon ECS services will be part of the architecture, each requiring specific permissions to various AWS services. The company wants to optimize the use of the underlying Amazon EC2 instances by bin packing the containers based on memory reservation. Which configuration would allow the Development team to meet these requirements MOST securely",
        "answers": [
          {
            "id": "1",
            "text": "Create a new Identity and Access Management (IAM) instance profile containing the required permissions for the various ECS services, then associate that instance role with the underlying EC2 instances",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then configure each ECS service to reference the associated IAM role",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then, create an IAM group and configure the ECS cluster to reference that group",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create four distinct IAM roles, each containing the required permissions for the associated ECS service, then configure each ECS task definition to referenсe the associated IAM role",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 67,
        "question": "A Developer must re-implement the business logic for an order fulfilment system. The business logic has to make requests to multiple vendors to decide where to purchase an item. The whole process can take up to a week to complete. What is the MOST efficient and SIMPLEST way to implement a system that meets these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Use AWS Step Functions to execute parallel Lambda functions, and join the results",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Create an AWS SQS for each vendor, poll the queue from a worker instance, and joint the results",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use AWS Lambda to asynchronously call a Lambda function for each vendor, and join the results",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use Amazon CloudWatch Events to orchestrate the Lambda functions",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 68,
        "question": "q68 - is placeholder, come back and delete this once all qs in",
        "answers": [
          {
            "id": "1",
            "text": "ans 1",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "ans 2",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "ans 3",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "ans 4",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "ans 5",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 69,
        "question": "A Developer is receiving HTTP 400: ThrottlingException errors intermittently when calling the Amazon CloudWatch API. When a call fails, no data is retrieved. What best practice should first be applied to address this issue?",
        "answers": [
          {
            "id": "1",
            "text": "Contact AWS Support for a limit increase",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use the AWS CLI to get the metrics",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Analyze the applications and remove the API call",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Retry the call with exponential backoff",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 70,
        "question": "An application is real-time processing millions of events that are received through an API. What service could be used to allow multiple consumers to process the data concurrently and MOST cost-effectively?",
        "answers": [
          {
            "id": "1",
            "text": "Amazon SNS with fanout to an SQS queue for each application",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Amazon SNS with fanout to an SQS FIFO (first-in, first-out) queue for each application",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon Kinesis Firehouse",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Amazon Kinesis Streams",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 71,
        "question": "Where should the appspec.yml file be placed in order for AWS CodeDeploy to work?",
        "answers": [
          {
            "id": "1",
            "text": "In the root of the application source code directory structure",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "In the bin folder along with all the complied code",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "In an S3 bucket",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "In the same folder as the application configuration files",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 72,
        "question": "An application will ingest data at a very high throughput from many sources and must store the data in an Amazon S3 bucket. Which service would BEST accomplish this task?",
        "answers": [
          {
            "id": "1",
            "text": "Amazon Kinesis Firehose",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Amazon S3 Acceleration Transfer",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon SQS",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Amazon SNS",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 73,
        "question": "A Developer is creating a Lambda function and will be using external libraries that are not included in the standard Lambda libraries. What action would minimize the Lambda compute time consumed?",
        "answers": [
          {
            "id": "1",
            "text": "Install the dependencies and external libraries at the beginning of the Lambda function",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create a Lambda deployment package that includes the external libraries",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Copy the external libraries to Amazon S3, and reference the external libraries to the S3 location",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Install the external libraries in Lambda to be available to all Lambda functions",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 74,
        "question": "During non-peak hours, a Developer wants to minimize the execution time of a full Amazon DynamoDB table scan without affecting normal workloads. The workloads average half of the strongly consistent read capacity units during non-peak hours. How would the Developer optimize this scan?",
        "answers": [
          {
            "id": "1",
            "text": "Use parallel scans while limiting the rate",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Use sequential scans",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Increase read capacity units during the scan operation",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Change consistency to eventually consistent during the scan operation",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 75,
        "question": "A large e-commerce site is being designed to deliver static objects from Amazon S3. The Amazon S3 bucket will server more than 300 GET requests per second. What should be done to optimize performance? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Integrate Amazon CloudFront with Amazon S3",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Enable Amazon S3 cross-region replication",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Delete expired Amazon S3 server log files",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Configure Amazon S3 lifecycle rules.Randomize Amazon S3 key name prefixes",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "Randomize Amazon S3 key name prefixes",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 76,
        "question": "A legacy service has an XML-based SOAP interface. The Developer wants to expose the functionality of the service to external clients with the Amazon API Gateway. Which technique will accomplish this?",
        "answers": [
          {
            "id": "1",
            "text": "Create a RESTful API with the API Gateway; transform the incoming JSON into a valid XML message for the SOAP interface using mapping templates",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Create a RESTful API with the API Gateway; pass the incoming JSON to the SOAP interface through an Application Load Balancer",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create a RESTful API with the API Gateway; pass the incoming XML to the SOAP interface through an Application Load Balancer",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create a RESTful API with the API Gateway; transform the incoming XML into a valid message for the SOAP interface using mapping templates",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 77,
        "question": "A Developer has an application that can upload tens of thousands of objects per second to Amazon S3 in parallel within a single AWS account. As part of new requirements, data stored in S3 must use server side encryption with AWS KMS (SSE-KMS). After creating this change, performance of the application is slower. Which of the following is MOST likely the cause of the application latency?",
        "answers": [
          {
            "id": "1",
            "text": "Amazon S3 throttles the rate at which uploaded objects can be encrypted using Customer Master Keys",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "The AWS KMS API calls limit is less than needed to achieve the desired performance",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "The client encryption of the objects is using a poor algorithm",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "KMS requires that an alias be used to create an independent display name that can be mapped to a CM",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 78,
        "question": "A customer wants to deploy its source code on an AWS Elastic Beanstalk environment. The customer needs to perform deployment with minimal outage and should only use existing instances to retain application access log. What deployment policy would satisfy these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Rolling",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "All at once",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Rolling with an additional batch",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Immutable",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 79,
        "question": "A Developer has setup an Amazon Kinesis Stream with 4 shards to ingest a maximum of 2500 records per second. A Lambda function has been configured to process these records. In which order will these records be processed?",
        "answers": [
          {
            "id": "1",
            "text": "Lambda will receive each record in the reverse order it was placed into the stream following a LIFO (last-in, first-out) method",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Lambda will receive each record in the exact order it was placed into the stream following a FIFO (first­-in, first-out) method",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Lambda will receive each record in the exact order it was placed into the shard following a FIFO (first-in, first-out) method. There is no guarantee of order across shards.",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "The Developer can select FIFO, (first-in, first-out), LIFO (last-in, last-out), random, or request specific record using the getRecords API",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 80,
        "question": "An organization must store thousands of sensitive audio and video files in an Amazon S3 bucket. Organizational security policies require that all data written to this bucket be encrypted. How can compliance with this policy be ensured?",
        "answers": [
          {
            "id": "1",
            "text": "Use AWS Lambda to send notifications to the security team if unencrypted objects are pun in the bucket",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Configure an Amazon S3 bucket policy to prevent the upload of objects that do not contain the x-amz­-server-side-encryption header",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Create an Amazon CloudWatch event rule to verify that all objects stored in the Amazon S3 bucket are encrypted",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Configure an Amazon S3 bucket policy to prevent the upload of objects that contain the x-amz-server­side-encryption header",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 81,
        "question": "An application is designed to use Amazon SQS to manage messages from many independent senders. Each sender's messages must be processed in the order they are received. Which SQS feature should be implemented by the Developer?",
        "answers": [
          {
            "id": "1",
            "text": "Configure each sender with a unique MessageGroupId",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Enable MessageDeduplicationIds on the SQS queue",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Configure each message with unique MessageGroupIds",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Enable ContentBasedDeduplication on the SQS queue",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 82,
        "question": "A Developer created a dashboard for an application using Amazon API Gateway, Amazon S3, AWS Lambda, and Amazon RDS. The Developer needs an authentication mechanism allowing a user to sign in and view the dashboard. It must be accessible from mobile applications, desktops, and tablets, and must remember user preferences across platforms. Which AWS service should the Developer use to support this authentication scenario?",
        "answers": [
          {
            "id": "1",
            "text": "AWS KMS",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Amazon Cognito",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "AWS Directory Service",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Amazon IAM",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 83,
        "question": "A Lambda function is packaged for deployment to multiple environments, including development, test, production, etc. Each environment has unique set of resources such as databases, etc. How can the Lambda function use the resources for the current environment?",
        "answers": [
          {
            "id": "1",
            "text": "Apply tags to the Lambda functions",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Hardcore resources in the source code",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use environment variables for the Lambda functions",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Use separate function for development and production",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "ans 5",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 84,
        "question": "A Developer needs temporary access to resources in a second account. What is the MOST secure way to achieve this?",
        "answers": [
          {
            "id": "1",
            "text": "Use the Amazon Cognito user pools to get short-lived credentials for the second account",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create a dedicated IAM access key for the second account, and send it by mail",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create a cross-account access role, and use sts: AssumeRole API to get short-lived credentials",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Establish trust, and add an SSH key for the second account to the IAM user",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 85,
        "question": "A Developer needs to use AWS X-Ray to monitor an application that is deployed on EC2 instances. What steps have to be executed to perform the monitoring?",
        "answers": [
          {
            "id": "1",
            "text": "Deploy the X-Ray SDK with the application and use X-Ray annotation",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Install the X-Ray daemon and instrument the application code",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Install the X-Ray daemon and configure it to forward data to Amazon CloudWatch Events",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Deploy the X-Ray SDK with the application and instrument the application code",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 86,
        "question": "A Developer is creating an Auto Scaling group whose instances need to publish a custom metric to Amazon CloudWatch. Which method would be the MOST secure way to authenticate a CloudWatch PUT request?",
        "answers": [
          {
            "id": "1",
            "text": "Create an IAM user with PutMetricData permission and put the user credentials in a private repository; have applications pull the credentials as needed",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create an IAM user with PutMetricData permission, and modify the Auto Scaling launch configuration to inject the user credentials into the instance user data",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Modify the CloudWatch metric policies to allow the PutMetricData permission to instances from the Auto Scaling group",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create an IAM role with PutMetricData permission and modify the Auto Scaling launching configuration to launch instances using that role",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 87,
        "question": "[to do: add image]A Developer is working on an application that tracks hundreds of millions of product reviews in an Amazon DynamoDB table. The records include the data elements shown in the table. Which field, when used as the partition key, would result in the MOST consistent performance using DynamoDB?",
        "answers": [
          {
            "id": "1",
            "text": "starRating",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "reviewID",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "comment",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "productID",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 88,
        "question": "[to do: add image]A development team consists of 10 team members. Similar to a home directory for each team member, the manager wants to grant access to user-specific folders in an Amazon S3 bucket. For the team member with the username 'TeamMemberX', the snippet of the IAM policy looks like this. Instead of creating distinct policies for each team member, what approach can be used to make this policy snippet generic for all team members?",
        "answers": [
          {
            "id": "1",
            "text": "Use IAM policy condition",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Use IAM policy principal",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use IAM policy variables",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use IAM policy resource",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 89,
        "question": "A company needs to encrypt data at rest, but it wants to leverage an AWS managed service using its own master key. Which of the following AWS service can be used to meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "SSE with Amazon S3",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "SSE with AWS KMS",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Client-side encryption",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "AWS IAM roles and policies",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 90,
        "question": "A Developer has created a software package to be deployed on multiple EC2 instances using IAM roles. What actions could be performed to verify IAM access to get records from Amazon Kinesis Streams? (Select TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Use the AWS CLI to retrieve the IAM group",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Query Amazon EC2 metadata for in-line IAM policies",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Request a token from AWS STS, and perform a describe action",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Perform a get action using the '--dry-run' argument",
            "isCorrect": true
          },
          {
            "id": "5",
            "text": "Validate the IAM role policy with the IAM policy simulator",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 91,
        "question": "A company wants to implement a continuous integration for its workloads on AWS. The company wants to trigger unit test in its pipeline for commits-on its code repository, and wants to be notified of failure events in the pipeline. How can these requirements be met?",
        "answers": [
          {
            "id": "1",
            "text": "Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon SNS to trigger notifications of failure events",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Store the source code in GitHub. Create a CodePipeline to automate unit testing. Use Amazon SES to trigger notifications of failure events",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Store the source code on GitHub. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notifications of failure events",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Store the source code in AWS CodeCommit. Create a CodePipeline to automate unit testing. Use Amazon CloudWatch to trigger notification of failure events",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 92,
        "question": "An application takes 40 seconds to process instructions received in an Amazon SQS message. Assuming the SQS queue is configured with the default VisibilityTimeout value, what is the BEST way, upon receiving a message, to ensure that no other instances can retrieve a message that has already been processed or is currently being processed?",
        "answers": [
          {
            "id": "1",
            "text": "Use the ChangeMessageVisibility API to increase the VisibilityTimeout, then use the DeleteMessage API to delete the message.",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Use the DeleteMessage API call to delete the message from the queue, then call DeleteQueue API to remove the queue",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use the ChangeMessageVisibility API to decrease the timeout value, then use the DeleteMessage API to delete the message",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use the DeleteMessageVisibility API to cancel the VisibilityTimeout, then use the DeleteMessage API to delete the message",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 93,
        "question": "A Developer is developing an application that manages financial transactions. To improve security, multi-factor authentication (MFA) will be required as part of the login protocol. What services can the Developer use to meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Amazon DynamoDB to store MFA session data, and Amazon SNS to send MFA codes",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Amazon Cognito with MFA",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "AWS Directory Service",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "AWS IAM with MFA enabled",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 94,
        "question": "A Developer is writing transactions into a DynamoDB table called 'SystemUpdates' that has 5 write capacity units. Which option has the highest read throughput?",
        "answers": [
          {
            "id": "1",
            "text": "Eventually consistent reads of 5 read capacity units reading items that are 4 KB in size",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Strongly consistent reads of 5 read capacity units reading items that are 4 KB in size",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Eventually consistent reads of 15 read capacity units reading items that are 1 KB in size",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Strongly consistent reads of 15 read capacity units reading items that are 1 KB in size",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 95,
        "question": "A Developer has created an S3 bucket s3://mycoolapp and has enabled server across logging that points to the folder s3://mycoolapp/logs.The Developer moved 100 KB of Cascading Style Sheets (CSS) documents to the folder s3://mycoolapp/css, and then stopped work. When the developer came back a few days later, the bucket was 50 GB. What is the MOST likely cause of this situation?",
        "answers": [
          {
            "id": "1",
            "text": "The CSS files were not compressed and S3 versioning was enabled",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "S3 replication was enabled on the bucket",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Logging into the same bucket caused exponential log growth",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "An S3 lifecycle policy has moved the entire CSS file to S3 Infrequent Access",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 96,
        "question": "A Developer is testing a Docker-based application that uses the AWS SDK to interact with Amazon DynamoDB. In the local development environment, the application has used IAM access keys. The application is now ready for deployment onto an ECS cluster. How should the application authenticate with AWS services in production?",
        "answers": [
          {
            "id": "1",
            "text": "Configure an ECS task IAM role for the application to use",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Refactor the application to call AWS STS AssumeRole based on an instance role",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Configure AWS access key/secret access key environment variables with new credentials",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Configure the credentials file with a new access key/secret access key",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 97,
        "question": "A company is using AWS CodeBuild to compile a website from source code stored in AWS CodeCommit. A recent change to the source code has resulted in the CodeBuild project being unable to successfully compile the website. How should the Developer identify the cause of the failures?",
        "answers": [
          {
            "id": "1",
            "text": "Modify the buildspec.yml file to include steps to send the output of build commands to Amazon CloudWatch",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use a custom Docker image that includes the AWS X-Ray agent in the AWS CodeBuild project configuration",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Check the build logs of the failed phase in the last build attempt in the AWS CodeBuild project build history",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Manually re-run the build process on a local machine so that the output can be visualized",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 98,
        "question": "For a deployment using AWS CodeDeploy, what is the run order of the hooks for in-place deployments?",
        "answers": [
          {
            "id": "1",
            "text": "Before Install -> Application Stop -> Application Start -> After Install",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Application Stop -> Before Install -> After Install -> Application Start",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Before Install -> Application Stop -> Validate Service -> Application Start",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Application Stop -> Before Install -> Validate Service -> Application Start",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 99,
        "question": "[to do: add image] A Developer executed a AWS CLI command and received the error shown below. What action should the Developer perform to make this error human-readable?",
        "answers": [
          {
            "id": "1",
            "text": "Make a call to AWS KMS to decode the message",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use the AWS STS decode-authorization-message API to decode the message",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Use an open source decoding library to decode the message",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use the AWS IAM decode-authorization-message API to decode this message",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 100,
        "question": "A Developer uses AWS CodeDeploy to automate application deployment that connects to an external MySQL database. The Developer wants to securely access the encrypted secrets, such as API keys and database passwords. Which of the following solutions would involve the LEAST administrative effort?",
        "answers": [
          {
            "id": "1",
            "text": "Save the secrets in Amazon S3 with AWS KMS server-side encryption, and use a signed URL to access them by using the IAM role from Amazon EC2 instances",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use the instance metadata to store the secrets and to programmatically access the secrets from EC2 instances",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use the Amazon DynamoDB client-side encryption library to save the secrets in DynamoDB and to programmatically access the secrets from EC2 instances",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use AWS SSM Parameter Store to store the secrets and to programmatically access them by using the IAM role from EC2 instances",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 101,
        "question": "An application stops working with the following error: The specified bucket does not exist. Where is the BEST place to start the root cause analysis?",
        "answers": [
          {
            "id": "1",
            "text": "Check the Elastic Load Balancer logs for DeleteBucket requests",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Check the application logs in Amazon CloudWatch Logs for Amazon S3 DeleteBucket errors",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Check AWS X-Ray for Amazon S3 DeleteBucket alarms",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Check AWS X-Ray for Amazon S3 DeleteBucket alarms",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 102,
        "question": "A Developer will be using the AWS CLI on a local development server to manage AWS services. What can be done to ensure that the CLI uses the Developer's IAM permissions when making commands?",
        "answers": [
          {
            "id": "1",
            "text": "Specify the Developer's IAM access key ID and secret access key as parameters for each CLI command",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Run the aws configure CLI command, and provide the Developer's IAM access key ID and secret access key",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Specify the Developer's IAM user name and password as parameters for each CLI command",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use the Developer's IAM role when making the CLI command",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 103,
        "question": "An application stores images in an S3 bucket. Amazon S3 event notifications are used to trigger a Lambda function that resizes the images. Processing each image takes less than a second. How will AWS Lambda handle the additional traffic?",
        "answers": [
          {
            "id": "1",
            "text": "Lambda will scale out to execute the requests concurrently",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Lambda will handle the requests sequentially in the order received",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Lambda will process multiple images in a single execution",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Lambda will add more compute to each execution to reduce processing time",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 104,
        "question": "A company is building a stock trading application that requires sub-millisecond latency in processing trading requests. Amazon DynamoDB is used to store all the trading data that is used to process each request. After load testing the application, the development team found that due to data retrieval times, the latency requirement is not satisfied. Because of sudden high spikes in the number of requests, DynamoDB read capacity has to be significantly over-provisioned to avoid throttling. What steps should be taken to meet latency requirements and reduce the cost of running the application?",
        "answers": [
          {
            "id": "1",
            "text": "Add Global Secondary Indexes for trading data",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Store trading data in Amazon S3 and use Transfer Acceleration",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Add retries with exponential back-off for DynamoDB queries",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use DynamoDB Accelerator to cache trading data",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 105,
        "question": "A Developer created a Lambda function for a web application backend. When testing the Lambda function from the AWS Lambda console, the Developer can see that the function is being executed, but there is no log data being generated in Amazon CloudWatch Logs, even after several minutes. What could cause this situation?",
        "answers": [
          {
            "id": "1",
            "text": "Configure AWS CloudTrail logging to investigate the invocation failures",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Configure Dead Letter Queues by sending events to Amazon SQS for investigation",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Configure Amazon Simple Workflow Service to process any direct unprocessed events",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Configure AWS Config to process any direct unprocessed events",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 106,
        "question": "A Developer wants to use AWS X-Ray to trace a user request end-to-end throughput the software stack. The Developer made the necessary changes in the application tested it, and found that the application is able to send the traces to AWS X-Ray. However, when the application is deployed to an EC2 instance, the traces are not availableWhich of the following could create this situation? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "The traces are reaching X-Ray, but the Developer does not have access to view the records",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "The X-Ray daemon is not installed on the EC2 instance",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "The X-Ray endpoint specified in the application configuration is incorrect",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "The instance role does not have 'xray:BatchGetTraces' and 'xray:GetTraceGraph' permissions.The instance role does not have 'xray:PutTraceSegments' and 'xray:PutTelemetryRecords' permissions",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "The instance role does not have 'xray:PutTraceSegments' and 'xray:PutTelemetryRecords' permissions",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 107,
        "question": "An application has hundreds of users. Each user may use multiple devices to access the application. The Developer wants to assign unique identifiers to these users regardless of the device they use. Which of the following methods should be used to obtain unique identifiers?",
        "answers": [
          {
            "id": "1",
            "text": "Create a user table in Amazon DynamoDB as key-value pairs of users and their devices. Use these keys as unique identifiers",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use IAM-generated access key IDs for the users as the unique identifier, but do not store secret keys",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Implement developer-authenticated identities by using Amazon Cognito, and get credentials for these identities",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Assign IAM users and roles to the users. Use the unique IAM resource ID as the unique identifier",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 108,
        "question": "What are the steps to using the AWS CLI to launch a templatized serverless application?",
        "answers": [
          {
            "id": "1",
            "text": "Use AWS CloudFormation get-template then CloudFormation execute-change-set",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use AWS CloudFormation validate-template then CloudFormation create-change-set",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use AWS CloudFormation package then CloudFormation deploy",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Use AWS CloudFormation create-stack then CloudFormation update-stack",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 109,
        "question": "A deployment package uses the AWS CLI to copy files into any S3 bucket in the account, using access keys stored in environment variables. The package is running on EC2 instances, and the instances have been modified to run with an assumed IAM role and a more restrictive policy that allows access to only one bucket. After the change, the Developer logs into the host and still has the ability to write into all of the S3 buckets in that account. What is the MOST likely cause of this situation?",
        "answers": [
          {
            "id": "1",
            "text": "An IAM inline policy is being used on the IAM role",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "An IAM managed policy is being used on the IAM role",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "The AWS CLI is corrupt and needs to be reinstalled",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "The AWS credential provider looks for instance profile credentials last",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 110,
        "question": "An application overwrites an object in Amazon S3, and then immediately reads the same object. Why would the application sometimes retrieve the old version of the object?",
        "answers": [
          {
            "id": "1",
            "text": "S3 overwrite PUTS are eventually consistent, so the application may read the old object",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "The application needs to add extra metadata to label the latest version when uploading to Amazon S3",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "All S3 PUTS are eventually consistent, so the application may read the old object",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "The application needs to explicitly specify latest version when retrieving the object",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 111,
        "question": "An application under development is required to store hundreds of video files. The data must be encrypted within the application prior to storage, with a unique key for each video file. How should the Developer code the application?",
        "answers": [
          {
            "id": "1",
            "text": "Use the KMS Encrypt API to encrypt the data. Store the encrypted data key and data",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use a cryptography library to generate an encryption key for the application. Use the encryption key to encrypt the data. Store the encrypted data",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use the KMS GenerateDataKey API to get a data key. Encrypt the data with the data key. Store the encrypted data key and data",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Upload the data to an S3 bucket using server side-encryption with an AWS KMS key",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 112,
        "question": "A developer is testing an application that invokes an AWS Lambda function asynchronously. During the testing phase, the Lambda function fails to process after two retries. How can the developer troubleshoot the failure?",
        "answers": [
          {
            "id": "1",
            "text": "Configure AWS CloudTrail logging to investigate the invocation failures",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Configure Dead Letter Queues by sending events to Amazon SQS for investigation",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Configure Amazon Simple Workflow Service to process any direct unprocessed events",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Configure AWS Config to process any direct unprocessed events",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 113,
        "question": "A developer is setting up Amazon API Gateway for their company's products. The API will be used by registered developers to query and update their environments. The company wants to limit the amount of requests end users can send for both cost and security reasons. Management wants to offer registered developers the option of buying larger packages that allow for more requests. How can the developer accomplish this with the LEAST amount of overhead management?",
        "answers": [
          {
            "id": "1",
            "text": "Enable throttling for the API Gateway stage. Set a value for both the rate and burst capacity. If a registered user chooses a larger package, create a stage for them, adjust the values, and share the new URL with them",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Set up Amazon CloudWatch API logging in API Gateway. Create a filter based on the user and requestTime fields and create an alarm on this filter. Write an AWS Lambda function to analyze the values and requester information, and respond accordingly. Set up the function as the target for the alarm. If a registered user chooses a larger package, update the Lambda code with the values",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Enable Amazon CloudWatch metrics for the API Gateway stage. Set up CloudWatch alarms based off the Count metric and the ApiName, Method, Resource, and Stage dimensions to alerts when request rates pass the threshold. Set the alarm action to Deny. If a registered user chooses a larger package, create a user-specific alarm and adjust the values",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Set up a default usage plan, specify values for the rate and burst capacity, and associate it with a stage. If a registered user chooses a larger package, create a custom plan with the appropriate values and associate the plan with the user",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 114,
        "question": "A developer is refactoring a monolithic application. The application takes a POST request and performs several operations. Some of the operations are in parallel while others run sequentially. These operations have been refactored into individual AWS Lambda functions. The POST request will be processed by Amazon API Gateway. How should the developer invoke the Lambda functions in the same sequence using API Gateway?",
        "answers": [
          {
            "id": "1",
            "text": "Use Amazon SQS to invoke the Lambda functions",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use an AWS Step Functions activity to run the Lambda functions",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use Amazon SNS to trigger the Lambda functions",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use an AWS Step Functions state machine to orchestrate the Lambda functions",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 115,
        "question": "A company is adding stored value (or gift card) capability to its highly popular casual gaming website. Users need to be able to trade this value for other users' items on the platform. This would require both users' records be updated as a single transaction, or both users' records to be completely rolled back. Which AWS database options can provide the transactional capability required for this new feature? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Amazon DynamoDB with operations made with the ConsistentRead parameter set to true",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Amazon ElastiCache for Memcached with operations made within a transaction block",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon Aurora MySQL with operations made within a transaction block",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Amazon DynamoDB with reads and writes made using Transact* operations",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Amazon Redshift with operations made within a transaction block",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 116,
        "question": "A developer is creating an AWS Lambda function that generates a new file each time it runs. Each new file must be checked into an AWS CodeCommit repository hosted in the same AWS account. How should the developer accomplish this?",
        "answers": [
          {
            "id": "1",
            "text": "When the Lambda function starts, use the Git CLI to clone the repository. Check the new file into the cloned repository and push the change",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "After the new file is created in Lambda, use cURL to invoke the CodeCommit API. Send the file to the repository",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use an AWS SDK to instantiate a CodeCommit client. Invoke the put_file method to add the file to the repository",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Upload the new to an Amazon S3 bucket. Create an AWS Step Function to accept S3 events. In the Step Function, add the new file to the repository",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 117,
        "question": "A developer must ensure that the IAM credentials used by an application in Amazon EC2 are not misused or compromised. What should the developer use to keep user credentials secure?",
        "answers": [
          {
            "id": "1",
            "text": "Environment variables",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "AWS credentials file",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Instance profile credentials",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Command line options",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 118,
        "question": "A company has an application where reading objects from Amazon S3 is based on the type of user. The user types are registered user and guest user. The company has 25,000 users and is growing. Information is pulled from an S3 bucket depending on the user type. Which approaches are recommended to provide access to both user types? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Provide a different access key and secret access key in the application code for registered users and guest users to provide read access to the objects",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Use S3 bucket policies to restrict read access to specific IAM users",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Use Amazon Cognito to provide access using authenticated and unauthenticated roles",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create a new IAM user for each user and grant read access",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "Use the AWS IAM service and let the application assume the different roles using the AWS Security Token Service (AWS STS) AssumeRole action depending on the type of user and provide read access to Amazon S3 using the assumed role",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 119,
        "question": "A company has 25,000 employees and is growing. The company is creating an application that will be accessible to its employees only. A developer is using Amazon S3 to store images and Amazon RDS to store application data. The company requires that all employee information remain in the legacy Security Assertion Markup Language (SAML) employee directory only and is not interested in mirroring any employee information on AWS. How can the developer provide authorized access for the employees who will be using this application so each employee can access their own application data only?",
        "answers": [
          {
            "id": "1",
            "text": "Use Amazon VPC and keep all resources inside the VPC, and use a VPC link for the S3 bucket with the bucket policy.",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use Amazon Cognito user pools, federate with the SAML provider, and use user pool groups with an IAM policy",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use an Amazon Cognito identity pool, federate with the SAML provider, and use an IAM condition key with a value for the cognito-identity.amazonaws.com:sub variable to grant access to the employees",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Create a unique IAM role for each employee and have each employee assume the role to access the application so they can access their personal data only",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 120,
        "question": "A company has developed a new serverless application using AWS Lambda functions that will be deployed using the AWS Serverless Application Model (AWS SAM) CLI. Which step should the developer complete prior to deploying the application?",
        "answers": [
          {
            "id": "1",
            "text": "Compress the application to a .zip file and upload it into AWS Lambda",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Test the new AWS Lambda function by first tracing it in AWS X-Ray",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Bundle the serverless application using a SAM package",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 121,
        "question": "An application needs to encrypt data that is written to Amazon S3 where the keys are managed in an on-premises data center, and the encryption is handled by S3. Which type of encryption should be used?",
        "answers": [
          {
            "id": "1",
            "text": "Use server-side encryption with Amazon S3-managed keys",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use server-side encryption with AWS KMS-managed keys",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use client-side encryption with customer master keys",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Use server-side encryption with customer-provided keys",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 122,
        "question": "A development team is working on a mobile app that allows users to upload pictures to Amazon S3. The team expects the app will be used by hundreds of thousands of users during a single event simultaneously. Once the pictures are uploaded, the backend service will scan and parse the pictures for inappropriate content. Which approach is the MOST resilient way to achieve this goal, which also smooths out temporary volume spikes for the backend service?",
        "answers": [
          {
            "id": "1",
            "text": "Develop an AWS Lambda function to check the upload folder in the S3 bucket. If new uploaded pictures are detected, the Lambda function will scan and parse them",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Once a picture is uploaded to Amazon S3, publish the event to an Amazon SQS queue. Use the queue as an event source to trigger an AWS Lambda function. In the Lambda function, scan and parse the picture",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "When the user uploads a picture, invoke an API hosted in Amazon API Gateway. The API will invoke an AWS Lambda function to scan and parse the picture",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create a state machine in AWS Step Functions to check the upload folder in the S3 bucket. If a new picture is detected, invoke an AWS Lambda function to scan and parse it",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 123,
        "question": "A development team wants to run their container workloads on Amazon ECS. Each application container needs to share data with another container to collect logs and metrics. What should the developer team do to meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Create two pod specifications. Make one to include the application container and the other to include the other container. Link the two pods together",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Create two task definitions. Make one to include the application container and the other to include the other container. Mount a shared volume between the two tasks",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create one task definition. Specify both containers in the definition. Mount a shared volume between those two containers",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create a single pod specification. Include both containers in the specification. Mount a persistent volume to both containers",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 124,
        "question": "An ecommerce startup is preparing for an annual sales event. As the traffic to the company's application increases, the development team wants to be notified when the Amazon EC2 instance's CPU utilization exceeds 80%. Which solution will meet this requirement?",
        "answers": [
          {
            "id": "1",
            "text": "Create a custom Amazon CloudWatch alarm that sends a notification to an Amazon SNS topic when the CPU utilization exceeds 80%",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Create a custom AWS Cloud Trail alarm that sends a notification to an Amazon SNS topic when the CPU utilization exceeds 80%",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create a cron job on the EC2 instance that executes the –describe-instance-information command on the host instance every 15 minutes and sends the results to an Amazon SNS topic",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create an AWS Lambda function that queries the AWS CloudTrail logs for the CPUUtilization metric every 15 minutes and sends a notification to an Amazon SNS topic when the CPU utilization exceeds 80%",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 125,
        "question": "An application running on Amazon EC2 opens connections to an Amazon RDS SQL Server database. The developer does not want to store the user name and password for the database in the code. The developer would also like to automatically rotate the credentials. What is the MOST secure way to store and access the database credentials?",
        "answers": [
          {
            "id": "1",
            "text": "Create an IAM role that has permissions to access the database. Attach the role to the EC2 instance",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use AWS Secrets Manager to store the credentials. Retrieve the credentials from Secrets Manager as needed",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Store the credentials in an encrypted text file in an Amazon S3 bucket. Configure the EC2 instance's user data to download the credentials from Amazon S3 as the instance boots",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Store the user name and password credentials directly in the source code. No further action is needed because the source code is stored in a private repository",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 126,
        "question": "A developer is updating an application deployed on AWS Elastic Beanstalk. The new version is incompatible with the old version. To successfully deploy the update, a full cutover to the new, updated version must be performed on all instances at one time, with the ability to roll back changes in case of a deployment failure in the new version. How can this be performed with the LEAST amount of downtime?",
        "answers": [
          {
            "id": "1",
            "text": "Use the Elastic Beanstalk All at once deployment policy to update all instances simultaneously",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Perform an Elastic Beanstalk Rolling with additional batch deployment",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Deploy the new version in a new Elastic Beanstalk environment and swap environment URLs",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Perform an Elastic Beanstalk Rolling deployment",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 127,
        "question": "A developer is writing a web application that must share secure documents with end users. The documents are stored in a private Amazon S3 bucket. The application must allow only authenticated users to download specific documents when requested, and only for a duration of 15 minutes. How can the developer meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Copy the documents to a separate S3 bucket that has a lifecycle policy for deletion after 15 minutes",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create a presigned S3 URL using the AWS SDK with an expiration time of 15 minutes",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Use server-side encryption with AWS KMS managed keys (SSE-KMS) and download the documents using HTTPS",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Modify the S3 bucket policy to only allow specific users to download the documents. Revert the change after 15 minutes",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 128,
        "question": "A company is developing a report executed by AWS Step Functions, Amazon CloudWatch shows errors in the Step Functions task state machine. To troubleshoot each task, the state input needs to be included along with the error message in the state output. Which coding practice can preserve both the original input and the error for the state?",
        "answers": [
          {
            "id": "1",
            "text": "Use ResultPath in a Catch statement to include the error with the original input",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Use InputPath in a Catch statement and set the value to null",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use Error Equals in a Retry statement to include the error with the original input",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use OutputPath in a Retry statement and set the value to $",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 129,
        "question": "[to do: add image] A developer receives the following error message when trying to launch or terminate an Amazon EC2 instance using a boto3 script. What should the developer do to correct this error message?",
        "answers": [
          {
            "id": "1",
            "text": "Assign an IAM role to the EC2 instance to allow necessary API calls on behalf of the client",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Implement an exponential backoff algorithm for optimizing the number of API requests made to Amazon EC2",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Increase the overall network bandwidth to handle higher API request rates",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Upgrade to the latest AWS CLI version so that boto3 can handle higher request rates",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 130,
        "question": "[to do: add image] Given the following AWS CloudFormation template. What is the MOST efficient way to reference the new Amazon S3 bucket from another AWS CloudFormation template?",
        "answers": [
          {
            "id": "1",
            "text": "Add an Export declaration to the Outputs section of the original template and use ImportValue in other templates",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Add Exported: true to the Contentbucket in the original template and use ImportResource in other templates",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create a custom AWS CloudFormation resource that gets the bucket name from the ContentBucket resource of the first stack",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Use Fn::Include to include the existing template in other templates and use the ContentBucket resource directly",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 131,
        "question": "A developer is using AWS CodeDeploy to deploy an application running on Amazon EC2. The developer wants to change the file permissions for a specific deployment file. Which lifecycle event should a developer use to meet this requirement?",
        "answers": [
          {
            "id": "1",
            "text": "AfterInstall",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "DownloadBundle",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "BeforeInstall",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "ValidateService",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 132,
        "question": "A developer is using Amazon DynamoDB to store application data. The developer wants to further improve application performance by reducing response times for read and write operations. Which DynamoDB feature should be used to meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Amazon DynamoDB Streams",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Amazon DynamoDB Accelerator",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Amazon DynamoDB global tables",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Amazon DynamoDB transactions",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 133,
        "question": "A developer is creating a script to automate the deployment process for a serverless application. The developer wants to use an existing AWS Serverless Application Model (AWS SAM) template for the application. What should the developer use for the project? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Call aws cloudformation package to create the deployment package. Call aws cloudformation deploy to deploy the package afterward",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Call sam package to create the deployment package. Call sam deploy to deploy the package afterward",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Call aws s3 cp to upload the AWS SAM template to Amazon S3. Call aws lambda update-function-code to create the application",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Create a ZIP package locally and call aws serverlessrepo create-application to create the application",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "Create a ZIP package and upload it to Amazon S3. Call aws cloudformation create-stack to create the application",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 134,
        "question": "A development team is designing a mobile app that requires multi-factor authentication. Which steps should be taken to achieve this? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Use Amazon Cognito to create a user pool and create users in the user pool",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Send multi-factor authentication text codes to users with the Amazon SNS Publish API call in the app code",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Enable multi-factor authentication for the Amazon Cognito user pool",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Use AWS IAM to create IAM users",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "Enable multi-factor authentication for the users created in AWS IAM",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 135,
        "question": "Two containerized microservices are hosted on Amazon EC2 ECS. The first microservice reads an Amazon RDS Aurora database instance, and the second microservice reads an Amazon DynamoDB table. How can each microservice be granted the minimum privileges?",
        "answers": [
          {
            "id": "1",
            "text": "Set ECS_ENABLE_TASK_IAM_ROLE to false on EC2 instance boot in ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the second microservice with an IAM role for ECS tasks with read-only access to DynamoDB",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Set ECS_ENABLE_TASK_IAM_ROLE to false on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Set ECS_ENABLE_TASK_IAM_ROLE to true on EC2 instance boot in the ECS agent configuration file. Run the first microservice with an IAM role for ECS tasks with read-only access for the Aurora database. Run the secondmicroservice with an IAM role for ECS tasks with read-only access to DynamoDB",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Set ECS_ENABLE_TASK_IAM_ROLE to true on EC2 instance boot in the ECS agent configuration file. Grant the instance profile role read-only access to the Aurora database and DynamoDB",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 136,
        "question": "A developer has written an AWS Lambda function using Java as the runtime environment. The developer wants to isolate a performance bottleneck in the code. Which steps should be taken to reveal the bottleneck?",
        "answers": [
          {
            "id": "1",
            "text": "Use the Amazon CloudWatch API to write timestamps to a custom CloudWatch metric. Use the CloudWatch console to analyze the resulting data",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use the AWS X-Ray API to write trace data into X-Ray from strategic places within the code. Use the Amazon CloudWatch console to analyze the resulting data",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use the AWS X-Ray API to write trace data into X-Ray from strategic places within the code. Use the X-Ray console to analyze the resulting data",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Use the Amazon CloudWatch API to write timestamps to a custom CloudWatch metric. Use the AWS X-Ray console to analyze the resulting data",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 137,
        "question": "A developer added a new feature to an application running on an Amazon EC2 instance that uses Amazon SQS. After deployment, the developer noticed a significant increase in Amazon SQS costs. When monitoring the Amazon SQS metrics on Amazon CloudWatch, the developer found that on average one message per minute is posted on this queue. What can be done to reduce Amazon SQS costs for this application?",
        "answers": [
          {
            "id": "1",
            "text": "Increase the Amazon SQS queue polling timeout",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Scale down the Amazon SQS queue to the appropriate size for low traffic demand",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Configure push delivery via Amazon SNS instead of polling the Amazon SQS queue",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use an Amazon SQS first-in, first-out (FIFO) queue instead of a standard queue",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 138,
        "question": "A developer is building an application using an Amazon API Gateway REST API backend by an AWS Lambda function that interacts with an Amazon DynamoDB table. During testing, the developer observes high latency when making requests to the API. How can the developer evaluate the end-to-end latency and identify performance bottlenecks?",
        "answers": [
          {
            "id": "1",
            "text": "Enable AWS CloudTrail logging and use the logs to map each latency and bottleneck",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Enable and configure AWS X-Ray tracing on API Gateway and the Lambda function. Use X-Ray to trace and analyze user requests",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Enable Amazon CloudWatch Logs for the Lambda function. Enable execution logs for API Gateway to view and analyze user request logs",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Enable VPC Flow Logs to capture and analyze network traffic within the VPC",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 139,
        "question": "An IAM role is attached to an Amazon EC2 instance that explicitly denies access to all Amazon S3 API actions. The EC2 instance credentials file specifies the IAM access key and secret access key, which allow full administrative access. Given that multiple modes of IAM access are present for this EC2 instance, which of the following is correct?",
        "answers": [
          {
            "id": "1",
            "text": "The EC2 instance will only be able to list the S3 buckets",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "The EC2 instance will only be able to list the contents of one S3 bucket at a time",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "The EC2 instance will be able to perform all actions on any S3 bucket",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "The EC2 instance will not be able to perform any S3 action on any S3 bucket",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 140,
        "question": "A development team uses AWS Elastic Beanstalk for application deployment. The team has configured the application version lifecycle policy to limit the number of application versions to 25. However, even with the lifecycle policy, the source bundle is deleted from the Amazon S3 source bucket. What should a developer do in the Elastic Beanstalk application version lifecycle settings to retain the source code in the S3 bucket?",
        "answers": [
          {
            "id": "1",
            "text": "Change the Set the application versions limit by total count setting to zero",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Disable the Lifecycle policy setting",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Change the Set the application version limit by age setting to zero.",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Set Retention to Retain source bundle in S3",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 141,
        "question": "A developer has built a market application that stores pricing data in Amazon DynamoDB with Amazon ElastiCache in front. The prices of items in the market change frequently. Sellers have begun complaining that, after they update the price of an item, the price does not actually change in the product listing. What could be causing this issue?",
        "answers": [
          {
            "id": "1",
            "text": "The cache is not being invalidated when the price of the item is changed",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "The price of the item is being retrieved using a write-through ElastiCache cluster",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "The DynamoDB table was provisioned with insufficient read capacity",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "The DynamoDB table was provisioned with insufficient write capacity",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 142,
        "question": "A developer is provided with an HTTPS clone URL for an AWS CodeCommit repository. What needs to be configured before cloning this repository?",
        "answers": [
          {
            "id": "1",
            "text": "Use AWS KMS to set up public and private keys for use with AWS CodeCommit",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Set up the Git credential helper to use an AWS credential profile, and enable the helper to send the path to the repositories",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Use AWS Certificate Manager to provision public and private SSL/TLS certificates",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Generate encryption keys using AWS CloudHSM, then export the key for use with AWS CodeCommit",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 143,
        "question": "What is required to trace Lambda-based applications with AWS X-Ray?",
        "answers": [
          {
            "id": "1",
            "text": "Send logs from the Lambda application to an S3 bucket; trigger a Lambda function from the bucket to send data to AWS X-Ray",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Trigger a Lambda function from the application logs in Amazon CloudWatch to submit tracing data to AWS X-Ray",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use an IAM execution role to give the Lambda function permissions and enable tracing",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Update and add AWS X-Ray daemon code to relevant parts of the Lambda function to set up the trace",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 144,
        "question": "A development team is building a new application that will run on Amazon EC2 and use Amazon DynamoDB as a storage layer. The developers all have assigned IAM user accounts in the same IAM group. The developers currently can launch EC2 instances, and they need to be able to launch EC2 instances with an instance role allowing access to Amazon DynamoDB. Which AWS IAM changes are needed when creating an instance role to provide this functionality?",
        "answers": [
          {
            "id": "1",
            "text": "Create an IAM permission policy attached to the role that allows access to DynamoDB. Add a trust policy to the role that allows DynamoDB to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:GetRole and iam:PassRole permissions for the role",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create an IAM permissions policy attached to the role that allows access to DynamoDB. Add a trust policy to the role that allows Amazon EC2 to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:PassRole permission for the role",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Create an IAM permission policy attached to the role that allows access to Amazon EC2. Add a trust policy to the role that allows DynamoDB to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:PassRole permission for the role",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create an IAM permissions policy attached to the role that allows access to DynamoDB. Add a trust policy to the role that allows Amazon EC2 to assume the role. Attach a permissions policy to the development group in AWS IAM that allows developers to use the iam:GetRole permission for the role",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 145,
        "question": "A developer converted an existing program to an AWS Lambda function in the console. The program runs properly on a local laptop, but shows an 'Unable to import module' error when tested in the Lambda console. Which of the following can fix the error?",
        "answers": [
          {
            "id": "1",
            "text": "Install the missing module and specify the current directory as the target. Create a ZIP file to include all files under the current directory, and upload the ZIP file",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Install the missing module in a lib directory. Create a ZIP file to include all files under the lib directory, and upload the ZIP file as dependency file",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "In the Lambda code, invoke a Linux command to install the missing modules under the /usr/lib directory",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "In the Lambda console, create a LB_LIBRARY_PATH environment and specify the value for the system library plan",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 146,
        "question": "A front-end web application is using Amazon Cognito user pools to handle the user authentication flow. A developer is integrating Amazon DynamoDB into the application using the AWS SDK for JavaScript. How would the developer securely call the API without exposing the access or secret keys?",
        "answers": [
          {
            "id": "1",
            "text": "Configure Amazon Cognito identity pools and exchange the JSON Web Token (JWT) for temporary credentials",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Run the web application in an Amazon EC2 instance with the instance profile configured",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Hardcore the credentials, use Amazon S3 to host the web application, and enable server-side encryption",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use Amazon Cognito user pool JSON Web Tokens (JWITs) to access the DynamoDB APIs",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 147,
        "question": "A developer needs to manage AWS infrastructure as code and must be able to deploy multiple identical copies of the infrastructure, stage changes, and revert to previous versions. Which approach addresses these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Use cost allocation reports and AWS OpsWorks to deploy and manage the infrastructure",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use Amazon CloudWatch metrics and alerts along with resource tagging to deploy and manage the infrastructure",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use AWS Elastic Beanstalk and AWS CodeCommit to deploy and manage the infrastructure",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use AWS CloudFormation and AWS CodeCommit to deploy and manage the infrastructure",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 148,
        "question": "A Developer needs to deploy an application running on AWS Fargate using Amazon ECS. The application has environment variables that must be passed to a container for the application to initialize. How should the environment variables be passed to the container?",
        "answers": [
          {
            "id": "1",
            "text": "Define an array that includes the environment variables under the environment parameter within the service definition",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Define an array that includes the environment variables under the environment parameter within the task definition",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Define an array that includes the environment variables under the entryPoint parameter within the task definition",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Define an array that includes the environment variables under the entryPoint parameter within the service definition",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 149,
        "question": "A company's fleet of Amazon EC2 instances receives data from millions of users through an API. The servers batch the data, add an object for each user, and upload the objects to an S3 bucket to ensure high access rates. The object attributes are Customer ID, Server ID, TS-Server (TimeStamp and Server ID), the size of the object, and a timestamp. A Developer wants to find all the objects for a given user collected during a specified time range. After creating an S3 object created event, how can the Developer achieve this requirement?",
        "answers": [
          {
            "id": "1",
            "text": "Execute an AWS Lambda function in response to the S3 object creation events that creates an Amazon DynamoDB record for every object with the Customer ID as the partition key and the Server ID as the sort key. Retrieve all the records using the Customer ID and Server ID attributes",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Execute an AWS Lambda function in response to the S3 object creation events that creates an Amazon Redshift record for every object with the Customer ID as the partition key and TS-Server as the sort key. Retrieve all the records using the Customer ID and TS-Server attributes",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Execute an AWS Lambda function in response to the S3 object creation events that creates an Amazon DynamoDB record for every object with the Customer ID as the partition key and TS-Server as the sort key. Retrieve all the records using the Customer ID and TS-Server attributes",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Execute an AWS Lambda function in response to the S3 object creation events that creates an Amazon Redshift record for every object with the Customer ID as the partition key and the Server ID as the sort key. Retrieve all the records using the Customer ID and Server ID attributes",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 150,
        "question": "A company is managing a NoSQL database on-premises to host a critical component of an application, which is starting to have scaling issues. The company wants to migrate the application to Amazon DynamoDB with the following considerations: Optimize frequent queries. Reduce read latencies. Plan for frequent queries on certain key attributes of the table. Which solution would help achieve these objectives?",
        "answers": [
          {
            "id": "1",
            "text": "Create global secondary indexes on keys that are frequently queried. Add the necessary attributes into the indexes",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Create local secondary indexes on keys that are frequently queried. DynamoDB will fetch needed attributes from the table",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create DynamoDB global tables to speed up query responses. Use a scan to fetch data from the table",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create an AWS Auto Scaling policy for the DynamoDB table",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 151,
        "question": "A developer is writing an application that will process data delivered into an Amazon S3 bucket. The data is delivered approximately 10 times a day, and the developer expects the data will be processed in less than 1 minute, on average. How can the developer deploy and invoke the application with the lowest cost and lowest latency?",
        "answers": [
          {
            "id": "1",
            "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch alarm triggered by an S3 object upload",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Deploy the application as an AWS Lambda function and invoke it with an S3 event notification",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Deploy the application as an AWS Lambda function and invoke it with an Amazon CloudWatch scheduled event",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Deploy the application onto an Amazon EC2 instance and have it poll the S3 bucket for new objects",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 152,
        "question": "A company is using Amazon API Gateway to manage its public-facing API. The CISO requires that the APIs be used by test account users only. What is the MOST secure way to restrict API access to users of this particular AWS account?",
        "answers": [
          {
            "id": "1",
            "text": "Client-side SSL certificates for authentication",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "API Gateway resource policies",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Cross-origin resource sharing (CORS)",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Usage plans",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 153,
        "question": "A Developer is migrating existing applications to AWS. These applications use MongoDB as their primary data store, and they will be deployed to Amazon EC2 instances. Management requires that the Developer minimize changes to applications while using AWS services. Which solution should the Developer use to host MongoDB in AWS?",
        "answers": [
          {
            "id": "1",
            "text": "Install MongoDB on the same instance where the application is running",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Deploy Amazon DocumentDB in MongoDB compatibility mode",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Use Amazon API Gateway to translate API calls from MongoDB to Amazon DynamoDB",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Replicate the existing MongoDB workload to Amazon DynamoDB",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 154,
        "question": "A company requires that AWS Lambda functions written by Developers log errors so System Administrators can more effectively troubleshoot issues. What should the Developers implement to meet this need?",
        "answers": [
          {
            "id": "1",
            "text": "Publish errors to a dedicated Amazon SQS queue",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create an Amazon CloudWatch Events event trigger based on certain Lambda events",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Report errors through logging statements in Lambda function code",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Set up an Amazon SNS topic that sends logging statements upon failure",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 155,
        "question": "A Developer is writing an application that runs on Amazon EC2 instances in an Auto Scaling group. The application data is stored in an Amazon DynamoDB table and records are constantly updated by all instances. An instance sometimes retrieves old data. The Developer wants to correct this by making sure the reads are strongly consistent. How can the Developer accomplish this?",
        "answers": [
          {
            "id": "1",
            "text": "Set ConsistentRead to true when calling Getltem",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Create a new DynamoDB Accelerator (DAX) table",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Set Consistency to strong when calling UpdateTable",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use the GetShardIterator command",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 156,
        "question": "A Developer has an application that must accept a large amount of incoming data streams and process the data before sending it to many downstream users. Which serverless solution should the Developer use to meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Amazon RDS MySQL stored procedure with AWS Lambda",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "AWS Direct Connect with AWS Lambda",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon Kinesis Data Streams with AWS Lambda",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Amazon EC2 bash script with AWS Lambda",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 157,
        "question": "An application is experiencing performance issues based on increased demand. This increased demand is on read-only historical records pulled from an Amazon RDS-hosted database with custom views and queries. A Developer must improve performance without changing the database structure. Which approach will improve performance and MINIMIZE management overhead?",
        "answers": [
          {
            "id": "1",
            "text": "Deploy Amazon DynamoDB, move all the data, and point to DynamoDB",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Deploy Amazon ElastiCache for Redis and cache the data for the application",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Deploy Memcached on Amazon EC2 and cache the data for the application",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Deploy Amazon DynamoDB Accelerator (DAX) on Amazon RDS to improve cache performance",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 158,
        "question": "A Developer has an Amazon DynamoDB table that must be in provisioned mode to comply with user requirements. The application needs to support the following: Average item size: 10 KB Item reads each second: 10 strongly consistent Item writes each second: 2 transactional Which read and write capacity cost-effectively meets these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Read 10; write 2",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Read 30; write 40",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Use on-demand scaling",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Read 300; write 400",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 159,
        "question": "A company wants to containerize an existing three-tier web application and deploy it to Amazon ECS Fargate. The application is using session data to keep track of user activities. Which approach would provide the BEST user experience?",
        "answers": [
          {
            "id": "1",
            "text": "Provision a Redis cluster in Amazon ElastiCache and save the session data in the cluster",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create a session table in Amazon Redshift and save the session data in the database table",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Enable session stickiness in the existing Network Load Balancer and manage the session data in the container",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Use an Amazon S3 bucket as data store and save the session data in the bucket",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 160,
        "question": "An application is using a single-node Amazon ElastiCache for Redis instance to improve read performance. Over time, demand for the application has increased exponentially, which has increased the load on the ElastiCache instance. It is critical that this cache layer handles the load and is resilient in case of node failures. What can the Developer do to address the load and resiliency requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Add a read replica instance",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Migrate to a Memcached cluster",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Migrate to an Amazon Elasticsearch Service cluster",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Vertically scale the ElastiCache instance",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 161,
        "question": "A Developer is investigating an application's performance issues. The application consists of hundreds of microservices, and a single API call can potentially have a deep call stack. The Developer must isolate the component that is causing the issue. Which AWS service or feature should the Developer use to gather information about what is happening and isolate the fault?",
        "answers": [
          {
            "id": "1",
            "text": "AWS X-Ray",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "VPC Flow Logs",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon GuardDuty",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Amazon Macie",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 162,
        "question": "A Company runs continuous integration/continuous delivery (CI/CD) pipelines for its application on AWS CodePipeline. A Developer must write unit tests and run them as part of the pipelines before staging the artifacts for testing. How should the Developer incorporate unit tests as part of CI/CD pipelines?",
        "answers": [
          {
            "id": "1",
            "text": "Create a separate CodePipeline pipeline to run unit tests",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Update the AWS CodeBuild specification to include a phase for running unit tests",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Install the AWS CodeDeploy agent on an Amazon EC2 instance to run unit tests",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create a testing branch in AWS CodeCommit to run unit tests",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 163,
        "question": "An application has the following requirements: Performance efficiency of seconds with up to a minute of latency. The data storage size may grow up to thousands of terabytes. Per-message sizes may vary between 100 KB and 100 MB. Data can be stored as key/value stores supporting eventual consistency. What is the MOST cost-effective AWS service to meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Amazon DynamoDB",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Amazon S3",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon RDS (with a MySQL engine)",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Amazon ElastiCache",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 164,
        "question": "A Developer must allow guest users without logins to access an Amazon Cognito-enabled site to view files stored within an Amazon S3 bucket. How should the Developer meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Create a blank user ID in a user pool, add to the user group, and grant access to AWS resources",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create a new identity pool, enable access to authenticated identities, and grant access to AWS resources",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create a new user pool, enable access to authenticated identifies, and grant access to AWS resources",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create a new user pool, disable authentication access, and grant access to AWS resources",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 165,
        "question": "A Developer has written code for an application and wants to share it with other Developers on the team to receive feedback. The shared application code needs to be stored long-term with multiple versions and batch change tracking. Which AWS service should the Developer use?",
        "answers": [
          {
            "id": "1",
            "text": "AWS CodeBuild",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Amazon S3",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "AWS CodeCommit",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "AWS Cloud9",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 166,
        "question": "A Developer has discovered that an application responsible for processing messages in an Amazon SQS queue is routinely falling behind. The application is capable of processing multiple messages in one execution, but is only receiving one message at a time. What should the Developer do to increase the number of messages the application receives?",
        "answers": [
          {
            "id": "1",
            "text": "Call the ChangeMessageVisibility API for the queue and set MaxNumberOfMessages to a value greater than the default of 1",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Call the AddPermission API to set MaxNumberOfMessages for the ReceiveMessage action to a value greater than the default of 1",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Call the ReceiveMessage API to set MaxNumberOfMessages to a value greater than the default of 1",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Call the SetQueueAttributes API for the queue and set MaxNumberOfMessages to a value greater than the default of 1",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 167,
        "question": "A Developer registered an AWS Lambda function as a target for an Application Load Balancer (ALB) using a CLI command. However, the Lambda function is not being invoked when the client sends requests through the ALB. Why is the Lambda function not being invoked?",
        "answers": [
          {
            "id": "1",
            "text": "A Lambda function cannot be registered as a target for an ALB",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "A Lambda function can be registered with an ALB using AWS Management Console only",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "The permissions to invoke the Lambda function are missing",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Cross-zone is not enabled on the ALB",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 168,
        "question": "A company provides APIs as a service and commits to a service level agreement (SLA) with all its users. To comply with each SLA, what should the company do?",
        "answers": [
          {
            "id": "1",
            "text": "Enable throttling limits for each method in Amazon API Gateway",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create a usage plan for each user and request API keys to access the APIs",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Enable API rate limiting in Amazon Cognito for each user.",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Enable default throttling limits for each stage after deploying the APIs",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 169,
        "question": "A Developer is preparing a deployment package using AWS CloudFormation. The package consists of two separate templates: one for the infrastructure and one for the application. The application has to be inside the VPC that is created from the infrastructure template. How can the application stack refer to the VPC created from the infrastructure template?",
        "answers": [
          {
            "id": "1",
            "text": "Use the Ref function to import the VPC into the application stack from the infrastructure template",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Use the export flag in the infrastructure template, and then use the Fn::ImportValue function in the application template",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use the DependsOn attribute to specify that the application instance depends on the VPC in the application template",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use the Fn::GetAtt function to include the attribute of the VPC in the application template",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 170,
        "question": "A Developer needs to create an application that supports Security Assertion Markup Language (SAML) and Facebook authentication. It must also allow access to AWS services, such as Amazon DynamoDB. Which AWS service or feature will meet these requirements with the LEAST amount of additional coding?",
        "answers": [
          {
            "id": "1",
            "text": "AWS AppSync",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Amazon Cognito identity pools",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon Cognito user pools",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Amazon Lambda@Edge",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 171,
        "question": "A Developer is trying to monitor an application's status by running a cron job that returns 1 if the service is up and 0 if the service is down. The Developer created code that uses an AWS CLI put-metric-alarm command to publish the custom metrics to Amazon CloudWatch and create an alarm. However, the Developer is unable to create an alarm as the custom metrics do not appear in the CloudWatch console. What is causing this issue?",
        "answers": [
          {
            "id": "1",
            "text": "Sending custom metrics using the CLI is not supported",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "The Developer needs to use the put-metric-data command",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "The Developer must use a unified CloudWatch agent to publish custom metrics",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "The code is not running on an Amazon EC2 instance",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 172,
        "question": "A Developer has written an application that runs on Amazon EC2 instances and generates a value every minute. The Developer wants to monitor and graph the values generated over time without logging in to the instance each time. Which approach should the Developer use to achieve this goal?",
        "answers": [
          {
            "id": "1",
            "text": "Use the Amazon CloudWatch metrics reported by default for all EC2 instances. View each value from the CloudWatch console",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Develop the application to store each value in a file on Amazon S3 every minute with the timestamp as the name",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Publish each generated value as a custom metric to Amazon CloudWatch using available AWS SDKs",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Store each value as a variable and add the variable to the list of EC2 metrics that should be reported to the Amazon CloudWatch console",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 173,
        "question": "A Development team decides to adopt a continuous integration/continuous delivery (CI/CD) process using AWS CodePipeline and AWS CodeCommit for a new application. However, management wants a person to review and approve the code before it is deployed to production. How can the Development team add a manual approver to the CI/CD pipeline?",
        "answers": [
          {
            "id": "1",
            "text": "Use AWS SES to send an email to approvers when their action is required. Develop a simple application that allows approvers to accept or reject a build. Invoke an AWS Lambda function to advance the pipeline when a build is accepted",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "If approved, add an approved tag when pushing changes to the CodeCommit repository. CodePipeline will proceed to build and deploy approved commits without interruption",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Add an approval step to CodeCommit. Commits will not be saved until approved",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Add an approval action to the pipeline. Configure the approval action to publish to an Amazon SNS topic when approval is required. The pipeline execution will stop and wait for an approval",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 174,
        "question": "A Developer is building a serverless application using AWS Lambda and must create a REST API using an HTTP GET method. What needs to be defined to meet this requirement? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "A Lambda@Edge function",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "An Amazon API Gateway with a Lambda function",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "An exposed GET method in an Amazon API Gateway",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "An exposed GET method in the Lambda function",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "An exposed GET method in Amazon Route 53",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 175,
        "question": "A Developer is writing an application in AWS Lambda. To simplify testing and deployments, the Developer needs the database connection string to be easily changed without modifying the Lambda code. How can this requirement be met?",
        "answers": [
          {
            "id": "1",
            "text": "Store the connection string as a secret in AWS Secrets Manager",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Store the connection string in an IAM user account",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Store the connection string in AWS KMS",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Store the connection string as a Lambda layer",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 176,
        "question": "A company is launching an ecommerce website and will host the static data in Amazon S3. The company expects approximately 1,000 transactions per second (TPS) for GET and PUT requests in total. Logging must be enabled to track all requests and must be retained for auditing purposes. What is the MOST cost-effective solution?",
        "answers": [
          {
            "id": "1",
            "text": "Enable AWS CloudTrail logging for the S3 bucket-level action and create a lifecycle policy to move the data from the log bucket to Amazon S3 Glacier in 90 days",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Enable S3 server access logging and create a lifecycle policy to expire the data in 90 days",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Enable AWS CloudTrail logging for the S3 bucket-level action and create a lifecycle policy to expire the data in 90 days",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Enable S3 server access logging and create a lifecycle policy to move the data to Amazon S3 Glacier in 90 days",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 177,
        "question": "A Developer decides to store highly secure data in Amazon S3 and wants to implement server-side encryption (SSE) with granular control of who can access the master key. Company policy requires that the master key be created, rotated, and disabled easily when needed, all for security reasons. Which solution should be used to meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "SSE with Amazon S3 managed keys (SSE-S3)",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "SSE with AWS KMS managed keys (SSE-KMS)",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "SSE with AWS Secrets Manager",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "SSE with customer-provided encryption keys",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 178,
        "question": "A Developer is migrating an on-premises application to AWS. The application currently takes user uploads and saves them to a local directory on the server. All uploads must be saved and made immediately available to all instances in an Auto Scaling group. Which approach will meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Use Amazon EBS and configure the application AMI to use a snapshot of the same EBS instance on boot",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use Amazon S3 and rearchitect the application so all uploads are placed in S3",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Use instance storage and share it between instances launched from the same Amazon Machine Image (AMI)",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use Amazon EBS and file synchronization software to achieve eventual consistency among the Auto Scaling group",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 179,
        "question": "A Developer implemented a static website hosted in Amazon S3 that makes web service requests hosted in Amazon API Gateway and AWS Lambda. The site is showing an error that reads: 'No 'Access-Control-Allow-Origin' header is present on the requested resource. Origin 'null' is therefore not allowed access.' What should the Developer do to resolve this issue?",
        "answers": [
          {
            "id": "1",
            "text": "Enable cross-origin resource sharing (CORS) on the S3 bucket",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Enable cross-origin resource sharing (CORS) for the method in API Gateway",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Add the Access-Control-Request-Method header to the request",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Add the Access-Control-Request-Headers header to the request",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 180,
        "question": "A Developer is building an application that needs to store data in Amazon S3. Management requires that the data be encrypted before it is sent to Amazon S3 for storage. The encryption keys need to be managed by the Security team. Which approach should the Developer take to meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Implement server-side encryption using customer-provided encryption keys (SSE-C)",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Implement server-side encryption by using a client-side master key",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Implement client-side encryption using an AWS KMS managed customer master key (CMK)",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Implement client-side encryption using Amazon S3 managed keys",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 181,
        "question": "A Developer has written an Amazon Kinesis Data Streams application. As usage grows and traffic increases over time, the application is regularly receiving ProvisionedThroughputExceededException error messages. Which steps should the Developer take to resolve the error? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Use Auto Scaling to scale the stream for better performance",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Increase the delay between the GetRecords call and the PutRecords call",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Increase the number of shards in the data stream",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Specify a shard iterator using the ShardIterator parameter",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "Implement exponential backoff on the GetRecords call and the PutRecords call",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 182,
        "question": "A Developer is publishing critical log data to a log group in Amazon CloudWatch Logs, which was created 2 months ago. The Developer must encrypt the log data using an AWS KMS customer master key (CMK) so future data can be encrypted to comply with the company's security policy. How can the Developer meet this requirement?",
        "answers": [
          {
            "id": "1",
            "text": "Use the CloudWatch Logs console and enable the encrypt feature on the log group",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use the AWS CLI create-log-group command and specify the key Amazon Resource Name (ARN)",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Use the KMS console and associate the CMK with the log group",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use the AWS CLI associate-kms-key command and specify the key Amazon Resource Name (ARN)",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 183,
        "question": "A Developer has code running on Amazon EC2 instances that needs read-only access to an Amazon DynamoDB table. What is the MOST secure approach the Developer should take to accomplish this task?",
        "answers": [
          {
            "id": "1",
            "text": "Create a user access key for each EC2 instance with read-only access to DynamoDB. Place the keys in the code. Redeploy the code as keys rotate",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Use an IAM role with an AmazonDynamoDBReadOnlyAccess policy applied to the EC2 instances",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Run all code with only AWS account root user access keys to ensure maximum access to services",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use an IAM role with Administrator access applied to the EC2 instance",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 184,
        "question": "A Developer migrated a web application to AWS. As part of the migration, the Developer implemented an automated continuous integration/continuous improvement (CI/CD) process using a blue/green deployment. The deployment provisions new Amazon EC2 instances in an Auto Scaling group behind a new Application Load Balancer. After the migration was completed, the Developer began receiving complaints from users getting booted out of the system. The system also requires users to log in after every new deployment. How can these issues be resolved?",
        "answers": [
          {
            "id": "1",
            "text": "Use rolling updates instead of a blue/green deployment",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Externalize the user sessions to Amazon ElastiCache",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Turn on sticky sessions in the Application Load Balancer",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Use multicast to replicate session information",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 185,
        "question": "A Developer wants to insert a record into an Amazon DynamoDB table as soon as a new file is added to an Amazon S3 bucket. Which set of steps would be necessary to achieve this?",
        "answers": [
          {
            "id": "1",
            "text": "Create an event with Amazon CloudWatch Events that will monitor the S3 bucket and then insert the records into DynamoDB",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Configure an S3 event to invoke a Lambda function that inserts records into DynamoDB",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Create a Lambda function that will poll the S3 bucket and then insert the records into DynamoDB",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create a cron job that will run at a scheduled time and insert the records into DynamoDB",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 186,
        "question": "A company has implemented AWS CodeDeploy as part of its cloud native CI/CD stack. The company enables automatic rollbacks while deploying a new version of a popular web application from in-place to Amazon EC2. What occurs if the deployment of the new version fails due to code regression?",
        "answers": [
          {
            "id": "1",
            "text": "The last known good deployment is automatically restored using the snapshot stored in Amazon S3",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "CodeDeploy switches the Amazon Route 53 alias records back to the known good green deployment and terminates the failed blue deployment",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "A new deployment of the last known version of the application is deployed with a new deployment ID",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "AWS CodePipeline promotes the most recent deployment with a SUCCEEDED status to production",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 187,
        "question": "A Developer uses Amazon S3 buckets for static website hosting. The Developer creates one S3 bucket for the code and another S3 bucket for the assets, such as image and video files. Access is denied when a user attempts to access the assets bucket from the code bucket, with the website application showing a 403 error. How should the Developer solve this issue?",
        "answers": [
          {
            "id": "1",
            "text": "Create an IAM role and apply it to the assets bucket for the code bucket to be granted access",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Edit the bucket policy of the assets bucket to allow access from the code bucket",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Edit the bucket policy of the assets bucket to open access to all principals",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Change the code bucket to use AWS Lambda functions instead of static website hosting",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 188,
        "question": "A company has implemented AWS CodePipeline to automate its release pipelines. The Development team is writing an AWS Lambda function what will send notifications for state changes of each of the actions in the stages. Which steps must be taken to associate the Lambda function with the event source?",
        "answers": [
          {
            "id": "1",
            "text": "Create a trigger that invokes the Lambda function from the Lambda console by selecting CodePipeline as the event source",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create an event trigger and specify the Lambda function from the CodePipeline console",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Create an Amazon CloudWatch alarm that monitors status changes in Code Pipeline and triggers the Lambda function",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Create an Amazon CloudWatch Events rule that uses CodePipeline as an event source",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 189,
        "question": "A Developer has built an application running on AWS Lambda using AWS Serverless Application Model (AWS SAM). What is the correct order of execution to successfully deploy the application?",
        "answers": [
          {
            "id": "1",
            "text": "1. Build the SAM template in Amazon EC2. 2. Package the SAM template to Amazon EBS storage. 3. Deploy the SAM template from Amazon EBS",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "1. Build the SAM template locally. 2. Package the SAM template onto Amazon S3. 3. Deploy the SAM template from Amazon S3",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "1. Build the SAM template locally. 2. Deploy the SAM template from Amazon S3. 3. Package the SAM template for use",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "1. Build the SAM template locally. 2. Package the SAM template from AWS CodeCommit. 3. Deploy the SAM template to CodeCommit",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 190,
        "question": "A company wants to migrate an imaging service to Amazon EC2 while following security best practices. The images are sourced and read from a non-public Amazon S3 bucket. What should a Developer do to meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Create an IAM user with read-only permissions for the S3 bucket. Temporarily store the user credentials in the Amazon EBS volume of the EC2 instance",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create an IAM user with read-only permissions for the S3 bucket. Temporarily store the user credentials in the user data of the EC2 instance",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create an EC2 service role with read-only permissions for the S3 bucket. Attach the role to the EC2 instance",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Create an S3 service role with read-only permissions for the S3 bucket. Attach the role to the EC2 instance",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 191,
        "question": "A Development team wants to immediately build and deploy an application whenever there is a change to the source code. Which approaches could be used to trigger the deployment? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Store the source code in an Amazon S3 bucket. Configure AWS CodePipeline to start whenever a file in the bucket changes",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Store the source code in an encrypted Amazon EBS volume. Configure AWS CodePipeline to start whenever a file in the volume changes",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Store the source code in an AWS CodeCommit repository. Configure AWS CodePipeline to start whenever a change is committed to the repository",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Store the source code in an Amazon S3 bucket. Configure AWS CodePipeline to start every 15 minutes",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "Store the source code in an Amazon EC2 instance's ephemeral storage. Configure the instance to start AWS CodePipeline whenever there are changes to the source code",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 192,
        "question": "An application ingests a large number of small messages and stores them in a database. The application uses AWS Lambda. A Development team is making changes to the application's processing logic. In testing, it is taking more than 15 minutes to process each message. The team is concerned the current backend may time out. Which changes should be made to the backend system to ensure each message is processed in the MOST scalable way?",
        "answers": [
          {
            "id": "1",
            "text": "Add the messages to an Amazon SQS queue. Set up and Amazon EC2 instance to poll the queue and process messages as they arrive",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Add the messages to an Amazon SQS queue. Set up Amazon EC2 instances in an Auto Scaling group to poll the queue and process the messages as they arrive",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Create a support ticket to increase the Lambda timeout to 60 minutes to allow for increased processing time",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Change the application to directly insert the body of the message into an Amazon RDS database",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 193,
        "question": "A Software Engineer developed an AWS Lambda function in Node.js to do some CPU-intensive data processing. With the default settings, the Lambda function takes about 5 minutes to complete. Which approach should a Developer take to increase the speed of completion?",
        "answers": [
          {
            "id": "1",
            "text": "Instead of using Node.js, rewrite the Lambda function using Python",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Instead of packaging the libraries in the ZIP file with the function, move them to a Lambda layer and use the layer with the function",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Allocate the maximum available CPU units to the function",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Increase the available memory to the function",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 194,
        "question": "An online retail company has deployed a serverless application with AWS Lambda, Amazon API Gateway, Amazon S3, and Amazon DynamoDB using AWS CloudFormation. The company rolled out a new release with major upgrades to the Lambda function and deployed the release to production. Subsequently, the application stopped working. Which solution should bring the application back up as quickly as possible?",
        "answers": [
          {
            "id": "1",
            "text": "Redeploy the application on Amazon EC2 so the Lambda function can resolve dependencies",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Migrate DynamoDB to Amazon RDS and redeploy the Lambda function",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Roll back the Lambda function to the previous version",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Deploy the latest Lambda function in a different Region",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 195,
        "question": "A Developer is writing an application that will run on Amazon EC2 instances in an Auto Scaling group. The Developer wants to externalize session state to support the application. Which services will meet these needs? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Amazon DynamoDB",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Amazon Cognito",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Amazon ElastiCache",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Amazon EBS",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "Amazon SQS",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 196,
        "question": "A Developer has a legacy application that is hosted on-premises. Other applications hosted on AWS depend on the on-premises application for proper functioning. In case of any application errors, the Developer wants to be able to use Amazon CloudWatch to monitor and troubleshoot all applications from one place. How can the Developer accomplish this?",
        "answers": [
          {
            "id": "1",
            "text": "Install an AWS SDK on the on-premises server to automatically send logs to CloudWatch",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Download the CloudWatch agent to the on-premises server. Configure the agent to use IAM user credentials with permissions for CloudWatch",
            "isCorrect": true
          },
          {
            "id": "3",
            "text": "Upload log files from the on-premises server to Amazon S3 and have CloudWatch read the files",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Upload log files from the on-premises server to an Amazon EC2 instance and have the instance forward the logs to CloudWatch",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 197,
        "question": "A company is developing an application that will be accessed through the Amazon API Gateway REST API. Registered users should be the only ones who can access certain resources of this API. The token being used should expire automatically and needs to be refreshed periodically. How can a Developer meet these requirements?",
        "answers": [
          {
            "id": "1",
            "text": "Create an Amazon Cognito identity pool, configure the Amazon Cognito Authorizer in API Gateway, and use the temporary credentials generated by the identity pool",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Create and maintain a database record for each user with a corresponding token and use an AWS Lambda authorizer in API Gateway",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Create an Amazon Cognito user pool, configure the Cognito Authorizer in API Gateway, and use the identity or access token",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Create an IAM user for each API user, attach an invoke permissions policy to the API, and use an IAM authorizer in API Gateway",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 198,
        "question": "A Developer is working on a serverless project based in Java. Initial testing shows a cold start takes about 8 seconds on average for AWS Lambda functions. What should the Developer do to reduce the cold start time? (Choose TWO)",
        "answers": [
          {
            "id": "1",
            "text": "Add the Spring Framework to the project and enable dependency injection",
            "isCorrect": true
          },
          {
            "id": "2",
            "text": "Reduce the deployment package by including only needed modules from the AWS SDK for Java",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Increase the memory allocation setting for the Lambda function",
            "isCorrect": false
          },
          {
            "id": "4",
            "text": "Increase the timeout setting for the Lambda function",
            "isCorrect": false
          },
          {
            "id": "5",
            "text": "Change the Lambda invocation mode from synchronous to asynchronous",
            "isCorrect": true
          }
        ]
      },
      {
        "id": 199,
        "question": "A Developer is leveraging a Border Gateway Protocol (BGP)-based AWS VPN connection to connect from on-premises to Amazon EC2 instances in the Developer's account. The Developer is able to access an EC2 instance in subnet A, but is unable to access an EC2 instance in subnet B in the same VPC. Which logs can the Developer use to verify whether the traffic is reaching subnet B?",
        "answers": [
          {
            "id": "1",
            "text": "VPN logs",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "VPN logs",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "VPC Flow Logs",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "AWS CloudTrail logs.",
            "isCorrect": false
          }
        ]
      },
      {
        "id": 200,
        "question": "A Developer has created a new AWS IAM user that has s3 putObject permission to write to a specific Amazon S3 bucket. This S3 bucket uses server-side encryption with AWS KMS managed keys (SSE-KMS) as the default encryption. Using the access key and secret key of the IAM user, the application received an access denied error when calling the PutObject API. How can this issue be resolved?",
        "answers": [
          {
            "id": "1",
            "text": "Update the policy of the IAM user to allow the s3 Encrypt action",
            "isCorrect": false
          },
          {
            "id": "2",
            "text": "Update the bucket policy of the S3 bucket to allow the IAM user to upload objects",
            "isCorrect": false
          },
          {
            "id": "3",
            "text": "Update the policy of the IAM user to allow the kms:GenerateDataKey action",
            "isCorrect": true
          },
          {
            "id": "4",
            "text": "Update the ACL of the S3 bucket to allow the IAM user to upload objects",
            "isCorrect": false
          }
        ]
      }
    ]
  }
}
